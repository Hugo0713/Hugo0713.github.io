<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>NVIDIA DPU Course</title>
    <url>/2025/02/22/NVIDIA-DPU-Course/</url>
    <content><![CDATA[<p>NVIDIA BlueField 数据处理单元(DPU)是一种高性能网络和计算加速器,专为现代数据中心设计。本文将介绍BlueField DPU的主要组件和功能。<br><span id="more"></span></p>
<h2 id="硬件平台"><a href="#硬件平台" class="headerlink" title="硬件平台"></a>硬件平台</h2><p>NVIDIA BlueField DPU目前主要有以下几代产品:</p>
<ul>
<li>BlueField-3 DPU</li>
<li>BlueField-2 DPU (支持InfiniBand/以太网双版本)</li>
<li>BlueField-1 系列控制器卡</li>
</ul>
<h2 id="软件架构"><a href="#软件架构" class="headerlink" title="软件架构"></a>软件架构</h2><h3 id="DOCA软件框架"><a href="#DOCA软件框架" class="headerlink" title="DOCA软件框架"></a>DOCA软件框架</h3><p>DOCA (Data center-on-chip Architecture)是NVIDIA为BlueField DPU开发的软件框架，包含：</p>
<h4 id="DOCA-SDK-v2-10-0"><a href="#DOCA-SDK-v2-10-0" class="headerlink" title="DOCA SDK (v2.10.0)"></a>DOCA SDK (v2.10.0)</h4><ul>
<li>RDMA加速SDK</li>
<li>网络加速SDK</li>
<li>安全加速SDK</li>
<li>存储加速SDK</li>
<li>数据路径加速(DPA) SDK</li>
<li>管理SDK</li>
</ul>
<h4 id="主要组件"><a href="#主要组件" class="headerlink" title="主要组件"></a>主要组件</h4><ul>
<li>统一通信接口(UCX)</li>
<li>RDMA verbs</li>
<li>GPUDirect</li>
<li>软件定义网络(SDN)</li>
<li>P4编程支持</li>
<li>在线加密</li>
<li>App Shield运行时安全</li>
</ul>
<h2 id="应用场景与功能"><a href="#应用场景与功能" class="headerlink" title="应用场景与功能"></a>应用场景与功能</h2><h3 id="1-网络加速"><a href="#1-网络加速" class="headerlink" title="1. 网络加速"></a>1. 网络加速</h3><h4 id="1-1-网络协议栈卸载"><a href="#1-1-网络协议栈卸载" class="headerlink" title="1.1 网络协议栈卸载"></a>1.1 网络协议栈卸载</h4><ul>
<li><p><strong>TCP/IP卸载</strong></p>
<ul>
<li>完整的TCP/IP协议栈处理</li>
<li>支持TCP Offload Engine (TOE)</li>
<li>降低主机CPU负载</li>
<li>减少网络延迟</li>
</ul>
</li>
<li><p><strong>RDMA技术</strong></p>
<ul>
<li>支持RoCE v1/v2 (RDMA over Converged Ethernet)</li>
<li>支持InfiniBand</li>
<li>零拷贝数据传输</li>
<li>内核旁路技术</li>
<li>QP (Queue Pair) 管理</li>
<li>支持RDMA Write/Read/Send/Receive操作</li>
</ul>
</li>
</ul>
<h4 id="1-2-网络虚拟化"><a href="#1-2-网络虚拟化" class="headerlink" title="1.2 网络虚拟化"></a>1.2 网络虚拟化</h4><ul>
<li><p><strong>SR-IOV (Single Root I/O Virtualization)</strong></p>
<ul>
<li>支持多达1000个VF (Virtual Function)</li>
<li>硬件级网络资源隔离</li>
<li>虚拟机直通技术</li>
</ul>
</li>
<li><p><strong>OVS (Open vSwitch) 加速</strong></p>
<ul>
<li>硬件卸载流表处理</li>
<li>支持OpenFlow协议</li>
<li>虚拟交换机性能优化</li>
</ul>
</li>
</ul>
<h4 id="1-3-高级网络特性"><a href="#1-3-高级网络特性" class="headerlink" title="1.3 高级网络特性"></a>1.3 高级网络特性</h4><ul>
<li><p><strong>流量管理</strong></p>
<ul>
<li>QoS (Quality of Service) 支持</li>
<li>带宽控制</li>
<li>流量整形</li>
<li>拥塞控制</li>
</ul>
</li>
<li><p><strong>网络安全</strong></p>
<ul>
<li>IPSec硬件加速</li>
<li>TLS/SSL卸载</li>
<li>防火墙规则处理</li>
<li>DDoS防护</li>
</ul>
</li>
</ul>
<h4 id="1-4-网络性能指标"><a href="#1-4-网络性能指标" class="headerlink" title="1.4 网络性能指标"></a>1.4 网络性能指标</h4><ul>
<li><p><strong>带宽能力</strong></p>
<ul>
<li>支持25/50/100/200/400GbE</li>
<li>BlueField-3支持高达800Gb/s带宽</li>
<li>双端口配置选项</li>
</ul>
</li>
<li><p><strong>延迟优化</strong></p>
<ul>
<li>端到端延迟&lt;1微秒</li>
<li>硬件时间戳支持</li>
<li>精确时间协议(PTP)支持</li>
</ul>
</li>
</ul>
<h3 id="1-5-网络编程模型"><a href="#1-5-网络编程模型" class="headerlink" title="1.5 网络编程模型"></a>1.5 网络编程模型</h3><ul>
<li><p><strong>DPDK支持</strong></p>
<ul>
<li>用户态网络驱动</li>
<li>轮询模式驱动(PMD)</li>
<li>零拷贝数据包处理</li>
<li>大页内存支持</li>
</ul>
</li>
<li><p><strong>P4可编程性</strong></p>
<ul>
<li>自定义数据包处理流水线</li>
<li>协议无关的包处理</li>
<li>灵活的转发规则定义</li>
</ul>
</li>
</ul>
<h4 id="1-6-相关网络知识"><a href="#1-6-相关网络知识" class="headerlink" title="1.6 相关网络知识"></a>1.6 相关网络知识</h4><ul>
<li><p><strong>网络分层模型</strong></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">应用层 (L7) - HTTP, FTP, SMTP等</span><br><span class="line">传输层 (L4) - TCP, UDP</span><br><span class="line">网络层 (L3) - IP, ICMP</span><br><span class="line">数据链路层 (L2) - 以太网, MAC</span><br><span class="line">物理层 (L1) - 物理介质</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>关键网络概念</strong></p>
<ul>
<li>MTU (Maximum Transmission Unit)</li>
<li>VLAN (Virtual LAN)</li>
<li>VXLAN (Virtual Extensible LAN)</li>
<li>ARP (Address Resolution Protocol)</li>
<li>BGP (Border Gateway Protocol)</li>
</ul>
</li>
</ul>
<h4 id="1-7-性能优化建议"><a href="#1-7-性能优化建议" class="headerlink" title="1.7 性能优化建议"></a>1.7 性能优化建议</h4><ul>
<li><p><strong>网络调优</strong></p>
<ul>
<li>启用巨帧(Jumbo Frame)</li>
<li>配置RSS (Receive Side Scaling)</li>
<li>优化中断亲和性</li>
<li>使用NUMA感知内存分配</li>
</ul>
</li>
<li><p><strong>最佳实践</strong></p>
<ul>
<li>合理规划网络拓扑</li>
<li>选择适当的网络模式</li>
<li>监控网络性能指标</li>
<li>定期进行性能测试</li>
</ul>
</li>
</ul>
<h3 id="2-存储加速"><a href="#2-存储加速" class="headerlink" title="2. 存储加速"></a>2. 存储加速</h3><ul>
<li>NVMe存储虚拟化</li>
<li>存储加密与压缩</li>
<li>零拷贝数据传输</li>
</ul>
<h3 id="3-安全功能"><a href="#3-安全功能" class="headerlink" title="3. 安全功能"></a>3. 安全功能</h3><ul>
<li>硬件加速加密</li>
<li>IPsec安全网关</li>
<li>零信任安全架构</li>
<li>运行时安全保护</li>
</ul>
<h3 id="4-虚拟化支持"><a href="#4-虚拟化支持" class="headerlink" title="4. 虚拟化支持"></a>4. 虚拟化支持</h3><ul>
<li>SR-IOV虚拟化</li>
<li>虚拟设备模拟</li>
<li>容器化工作负载支持</li>
</ul>
<p><a href="https://www.nvidia.cn/dpubook-3">参考来源</a><br><a href="https://www.nvidia.cn/dpubook-4">DOCA框架文档</a></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>NVIDIA</tag>
        <tag>AI辅助</tag>
      </tags>
  </entry>
  <entry>
    <title>解读尼采</title>
    <url>/2025/02/21/%E5%B0%BC%E9%87%87/</url>
    <content><![CDATA[<p>本笔记源于对视频<a href="https://www.bilibili.com/video/BV1X46iYaEgA/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=18b7c2df1803634b8448a869f204a1d6">解读尼采</a>的相关笔记与感悟，与笔者近期研究的存在主义相关。</p>
<p>To be continued……<br><span id="more"></span></p>
<h2 id="虚无主义"><a href="#虚无主义" class="headerlink" title="虚无主义"></a>虚无主义</h2><p>“Nihilism, is an inability to desire”</p>
<p>虚无主义，是一种欲望的缺失</p>
<h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>“nothing is true，everything is allowed.”</p>
<p>生活的核心驱动是“情和欲”(erotic), 人生追求无法基于理性？</p>
<h3 id="虚无的起源"><a href="#虚无的起源" class="headerlink" title="虚无的起源"></a>虚无的起源</h3><p>生活充满随机性，不一定具有逻辑</p>
<p>量化不一定合理</p>
<p>自洽就是真理吗？</p>
<p>“情欲匮乏”与“自我蔑视”self contempt</p>
]]></content>
      <categories>
        <category>哲学</category>
      </categories>
      <tags>
        <tag>尼采</tag>
      </tags>
  </entry>
  <entry>
    <title>espnet的enh训练任务分析笔记</title>
    <url>/2025/02/19/espnet%E7%9A%84enh.sh%E7%9A%84%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>This is the common recipe for ESPnet2 speech enhancement frontend.</strong><br><strong>这是 ESPnet2 语音增强前端的通用配方。</strong></p>
<p>本文为笔者学习espnet语音处理包语音增强部分的学习笔记，初稿为<strong>claude-3.5-sonnet</strong>辅助生成，后续会不断在此基础上更新，加入自己的理解。</p>
<span id="more"></span>
<p>以下为espnet工具包相关的网址</p>
<p><a href="https://github.com/espnet/espnet">ESPnet</a></p>
<p><a href="https://espnet.github.io/espnet/installation.html">espnet installation</a></p>
<p><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/enh1/enh.sh">enh.sh</a></p>
<p><a href="https://espnet.github.io/espnet/recipe/enh1.html">enh.sh官方文档</a></p>
<p>该enh.sh在espnet中的位置：<code>egs2/TEMPLATE/enh1/enh.sh</code> , 13 stages are included.</p>
<h2 id="训练任务流程"><a href="#训练任务流程" class="headerlink" title="训练任务流程"></a>训练任务流程</h2><ul>
<li>选择数据集</li>
<li>选择配置文件(可更改具体参数)</li>
<li>运行脚本</li>
</ul>
<p>以经典数据集<code>wsj0_2mix</code>为例，<a href="https://github.com/espnet/espnet/blob/master/egs2/wsj0_2mix">wsj0_2mix</a>,在<code>conf</code>目录的<code>tuning</code>子目录中选择配置，我选择的是<code>train_enh_rnn_tf.yaml</code>,该配置用于训练一个基于 RNN 的语音分离模型，其中<strong>tf</strong>后缀在这个配置文件名中代表 <strong>Time-Frequency domain（时频域）</strong></p>
<p>接着运行<code>run.sh</code>,比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./run.sh --stage 1 --stop_stage 6 --conf conf/tuning/train_enh_rnn_tf.yaml</span><br></pre></td></tr></table></figure>
<p>以下是run.sh的具体内容（因为很短就贴出来）<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"><span class="comment"># Set bash to 'debug' mode, it will exit on :</span></span><br><span class="line"><span class="comment"># -e 'error', -u 'undefined variable', -o ... 'error in pipeline', -x 'print commands',</span></span><br><span class="line"><span class="built_in">set</span> -e</span><br><span class="line"><span class="built_in">set</span> -u</span><br><span class="line"><span class="built_in">set</span> -o pipefail</span><br><span class="line"></span><br><span class="line">min_or_max=min <span class="comment"># "min" or "max". This is to determine how the mixtures are generated in local/data.sh.</span></span><br><span class="line">sample_rate=8k</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_set=<span class="string">"tr_<span class="variable">${min_or_max}</span>_<span class="variable">${sample_rate}</span>"</span></span><br><span class="line">valid_set=<span class="string">"cv_<span class="variable">${min_or_max}</span>_<span class="variable">${sample_rate}</span>"</span></span><br><span class="line">test_sets=<span class="string">"tt_<span class="variable">${min_or_max}</span>_<span class="variable">${sample_rate}</span> "</span></span><br><span class="line"></span><br><span class="line">./enh.sh \</span><br><span class="line">    --train_set <span class="string">"<span class="variable">${train_set}</span>"</span> \</span><br><span class="line">    --valid_set <span class="string">"<span class="variable">${valid_set}</span>"</span> \</span><br><span class="line">    --test_sets <span class="string">"<span class="variable">${test_sets}</span>"</span> \</span><br><span class="line">    --fs <span class="string">"<span class="variable">${sample_rate}</span>"</span> \</span><br><span class="line">    --lang en \</span><br><span class="line">    --ngpu 1 \</span><br><span class="line">    --local_data_opts <span class="string">"--sample_rate <span class="variable">${sample_rate}</span> --min_or_max <span class="variable">${min_or_max}</span>"</span> \</span><br><span class="line">    --enh_config conf/tuning/train_enh_dprnn_tasnet.yaml \</span><br><span class="line">    <span class="string">"<span class="variable">$@</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>注意到，调用的<code>enh.sh</code>,实际上就是TEMPLATE中的enh.sh(下文会具体分析)</p>
<p>1) 训练过程监控:</p>
<ul>
<li>查看日志: <code>tail -f exp/enh_train_*/train.log</code></li>
<li>查看关键指标：<code>grep "loss:" exp/enh_train_*/train.log</code></li>
</ul>
<p>2) 评估模型<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./run.sh --stage 7 --stop_stage 8 \</span><br><span class="line">    --conf conf/tuning/train_enh_rnn_tf.yaml</span><br></pre></td></tr></table></figure></p>
<p>查看评估结果:</p>
<ul>
<li>结果保存在 <code>exp/enh_train_*/RESULTS.txt</code></li>
<li>包含SI-SNR、SDR等指标</li>
</ul>
<p>3) 使用模型</p>
<p>对单个音频进行增强:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python -m espnet2.bin.enh_inference \</span><br><span class="line">    --audio_file /path/to/mixed.wav \</span><br><span class="line">    --config exp/enh_train_*/config.yaml \</span><br><span class="line">    --model_file exp/enh_train_*/valid.acc.best.pth \</span><br><span class="line">    --output_dir ./enhanced</span><br></pre></td></tr></table></figure></p>
<p>获取增强后的音频:</p>
<ul>
<li>增强结果保存在 <code>./enhanced</code> 目录</li>
<li>每个说话人的分离结果单独保存</li>
</ul>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>1) 训练中断后继续:</p>
<ul>
<li>直接运行相同的命令即可</li>
<li>ESPnet会自动加载最新的检查点</li>
</ul>
<p>2) 常见问题:</p>
<ul>
<li>内存不足: 减小 batch_size</li>
<li>显存不足: 减小 batch_size 或使用梯度累积</li>
<li>训练不收敛: 调整学习率或检查数据预处理</li>
</ul>
<p>3) 建议:</p>
<ul>
<li>先用小数据集测试流程</li>
<li>保存好配置文件和日志</li>
<li>定期备份实验结果</li>
</ul>
<h2 id="配置文件分析"><a href="#配置文件分析" class="headerlink" title="配置文件分析"></a>配置文件分析</h2><h3 id="基础训练参数"><a href="#基础训练参数" class="headerlink" title="基础训练参数"></a>基础训练参数</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">optim:</span> <span class="string">adam</span>  <span class="comment"># 优化器选择：adam优化器</span></span><br><span class="line"><span class="attr">init:</span> <span class="string">xavier_uniform</span>  <span class="comment"># 参数初始化方式：xavier均匀分布初始化</span></span><br><span class="line"><span class="attr">max_epoch:</span> <span class="number">100</span>  <span class="comment"># 最大训练轮数</span></span><br><span class="line"><span class="attr">batch_type:</span> <span class="string">folded</span>  <span class="comment"># 批次类型：folded表示按序列长度折叠</span></span><br><span class="line"><span class="attr">batch_size:</span> <span class="number">8</span>  <span class="comment"># 每批次样本数</span></span><br><span class="line"><span class="attr">num_workers:</span> <span class="number">4</span>  <span class="comment"># 数据加载器的并行工作进程数</span></span><br></pre></td></tr></table></figure>
<h3 id="优化器配置"><a href="#优化器配置" class="headerlink" title="优化器配置"></a>优化器配置</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">optim_conf:</span></span><br><span class="line">    <span class="attr">lr:</span> <span class="number">1.0e-03</span>          <span class="comment"># 初始学习率</span></span><br><span class="line">    <span class="attr">eps:</span> <span class="number">1.0e-08</span>         <span class="comment"># 数值稳定性参数</span></span><br><span class="line">    <span class="attr">weight_decay:</span> <span class="number">1.0e-7</span> <span class="comment"># L2正则化系数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 早停耐心值：验证集性能多少轮未改善就停止</span></span><br><span class="line"><span class="attr">patience:</span> <span class="number">10</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证集调度器判断标准</span></span><br><span class="line"><span class="attr">val_scheduler_criterion:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">valid</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">loss</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最佳模型保存标准</span></span><br><span class="line"><span class="attr">best_model_criterion:</span></span><br><span class="line"><span class="bullet">-</span>   <span class="bullet">-</span> <span class="string">valid</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">si_snr</span>    <span class="comment"># 尺度不变信噪比</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">max</span>       <span class="comment"># 最大化</span></span><br><span class="line"><span class="bullet">-</span>   <span class="bullet">-</span> <span class="string">valid</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">loss</span>      <span class="comment"># 损失值</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">min</span>       <span class="comment"># 最小化</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存最好的模型数量</span></span><br><span class="line"><span class="attr">keep_nbest_models:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 学习率调度器：当验证集性能不再提升时降低学习率</span></span><br><span class="line"><span class="attr">scheduler:</span> <span class="string">reducelronplateau</span></span><br><span class="line"><span class="attr">scheduler_conf:</span></span><br><span class="line">    <span class="attr">mode:</span> <span class="string">min</span>            <span class="comment"># 监控模式：最小化</span></span><br><span class="line">    <span class="attr">factor:</span> <span class="number">0.7</span>         <span class="comment"># 学习率降低因子</span></span><br><span class="line">    <span class="attr">patience:</span> <span class="number">1</span>         <span class="comment"># 调度器耐心值</span></span><br></pre></td></tr></table></figure>
<h3 id="损失函数配置"><a href="#损失函数配置" class="headerlink" title="损失函数配置"></a>损失函数配置</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># A list for criterions</span></span><br><span class="line"><span class="comment"># The overlall loss in the multi-task learning will be:</span></span><br><span class="line"><span class="comment"># loss = weight_1 * loss_1 + ... + weight_N * loss_N</span></span><br><span class="line"><span class="comment"># The default `weight` for each sub-loss is 1.0</span></span><br><span class="line"><span class="attr">criterions:</span></span><br><span class="line">  <span class="comment"># 第一个损失函数：均方误差(MSE)</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mse</span></span><br><span class="line">    <span class="attr">conf:</span></span><br><span class="line">      <span class="attr">compute_on_mask:</span> <span class="literal">True</span>   <span class="comment"># 在掩码上计算</span></span><br><span class="line">      <span class="attr">mask_type:</span> <span class="string">PSM</span>         <span class="comment"># 相位敏感掩码</span></span><br><span class="line">    <span class="attr">wrapper:</span> <span class="string">pit</span>             <span class="comment"># 用PIT（排列不变训练）包装</span></span><br><span class="line">    <span class="attr">wrapper_conf:</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">1.0</span>           <span class="comment"># 损失权重</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 第二个损失函数：L1损失</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">l1</span></span><br><span class="line">    <span class="attr">conf:</span></span><br><span class="line">      <span class="attr">compute_on_mask:</span> <span class="literal">False</span> <span class="comment"># 在波形上计算</span></span><br><span class="line">    <span class="attr">wrapper:</span> <span class="string">pit</span></span><br><span class="line">    <span class="attr">wrapper_conf:</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">1.0</span></span><br><span class="line">      <span class="attr">independent_perm:</span> <span class="literal">False</span> <span class="comment"># 使用前一个criterion的排列顺序</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 第三个损失函数：SI-SNR损失</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">si_snr</span></span><br><span class="line">    <span class="attr">conf:</span></span><br><span class="line">      <span class="attr">eps:</span> <span class="number">1.0e-7</span>           <span class="comment"># 数值稳定性参数</span></span><br><span class="line">    <span class="attr">wrapper:</span> <span class="string">pit</span></span><br><span class="line">    <span class="attr">wrapper_conf:</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">5.0</span>           <span class="comment"># 较大权重表示更重视此损失</span></span><br><span class="line">      <span class="attr">independent_perm:</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h3 id="模型架构配置"><a href="#模型架构配置" class="headerlink" title="模型架构配置"></a>模型架构配置</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">encoder:</span> <span class="string">stft</span> <span class="comment"># STFT编码器配置</span></span><br><span class="line"><span class="attr">encoder_conf:</span></span><br><span class="line">    <span class="attr">n_fft:</span> <span class="number">256</span>            <span class="comment"># FFT点数</span></span><br><span class="line">    <span class="attr">hop_length:</span> <span class="number">128</span>       <span class="comment"># 帧移</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># STFT解码器配置</span></span><br><span class="line"><span class="attr">decoder:</span> <span class="string">stft</span></span><br><span class="line"><span class="attr">decoder_conf:</span></span><br><span class="line">    <span class="attr">n_fft:</span> <span class="number">256</span></span><br><span class="line">    <span class="attr">hop_length:</span> <span class="number">128</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分离器配置：RNN架构</span></span><br><span class="line"><span class="attr">separator:</span> <span class="string">rnn</span></span><br><span class="line"><span class="attr">separator_conf:</span></span><br><span class="line">    <span class="attr">rnn_type:</span> <span class="string">blstm</span>       <span class="comment"># 双向LSTM</span></span><br><span class="line">    <span class="attr">num_spk:</span> <span class="number">2</span>           <span class="comment"># 说话人数量</span></span><br><span class="line">    <span class="attr">nonlinear:</span> <span class="string">relu</span>      <span class="comment"># 激活函数</span></span><br><span class="line">    <span class="attr">layer:</span> <span class="number">3</span>             <span class="comment"># RNN层数</span></span><br><span class="line">    <span class="attr">unit:</span> <span class="number">896</span>           <span class="comment"># 隐层单元数</span></span><br><span class="line">    <span class="attr">dropout:</span> <span class="number">0.5</span>        <span class="comment"># Dropout比率</span></span><br></pre></td></tr></table></figure>
<h2 id="enh-sh-的分析"><a href="#enh-sh-的分析" class="headerlink" title="enh.sh 的分析"></a>enh.sh 的分析</h2><h3 id="Stage-1前的配置介绍"><a href="#Stage-1前的配置介绍" class="headerlink" title="Stage 1前的配置介绍"></a>Stage 1前的配置介绍</h3><h4 id="基本设置"><a href="#基本设置" class="headerlink" title="基本设置"></a>基本设置</h4><ol>
<li><p><strong>bash调试模式设置</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> -e        <span class="comment"># 遇到错误就退出</span></span><br><span class="line"><span class="built_in">set</span> -u        <span class="comment"># 使用未定义变量时报错</span></span><br><span class="line"><span class="built_in">set</span> -o pipefail  <span class="comment"># 管道中任一命令失败则整个管道失败</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>辅助函数</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 日志函数：打印时间戳和调用位置信息</span></span><br><span class="line"><span class="function"><span class="title">log</span></span>() {</span><br><span class="line">    <span class="built_in">local</span> fname=<span class="variable">${BASH_SOURCE[1]##*/}</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">"<span class="subst">$(date '+%Y-%m-%dT%H:%M:%S')</span> (<span class="variable">${fname}</span>:<span class="variable">${BASH_LINENO[0]}</span>:<span class="variable">${FUNCNAME[1]}</span>) $*"</span></span><br><span class="line">} </span><br><span class="line"></span><br><span class="line"><span class="comment"># 求最小值函数：用于计算并行作业数</span></span><br><span class="line">min() </span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>注：让我比较疑惑的一个点是为什么不把日志重定向输出到一个文件？直接echo的话不会很长吗？</p>
<h4 id="必填参数"><a href="#必填参数" class="headerlink" title="必填参数"></a>必填参数</h4><ol>
<li><strong>数据集相关</strong></li>
</ol>
<ul>
<li><code>--train_set</code>: 训练集名称</li>
<li><code>--valid_set</code>: 验证集名称</li>
<li><code>--test_sets</code>: 测试集名称列表</li>
</ul>
<h4 id="选填参数"><a href="#选填参数" class="headerlink" title="选填参数"></a>选填参数</h4><ol>
<li><p><strong>基本配置参数</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">stage=1                <span class="comment"># 处理开始的阶段</span></span><br><span class="line">stop_stage=10000       <span class="comment"># 处理结束的阶段</span></span><br><span class="line">skip_data_prep=<span class="literal">false</span>   <span class="comment"># 是否跳过数据准备阶段</span></span><br><span class="line">skip_train=<span class="literal">false</span>       <span class="comment"># 是否跳过训练阶段  </span></span><br><span class="line">skip_eval=<span class="literal">false</span>        <span class="comment"># 是否跳过推理和评估阶段</span></span><br><span class="line">skip_packing=<span class="literal">true</span>      <span class="comment"># 是否跳过打包阶段</span></span><br><span class="line">skip_upload_hf=<span class="literal">true</span>    <span class="comment"># 是否跳过上传到HuggingFace阶段</span></span><br><span class="line">ngpu=1                 <span class="comment"># GPU数量(0表示使用CPU)</span></span><br><span class="line">num_nodes=1            <span class="comment"># 节点数量</span></span><br><span class="line">nj=32                  <span class="comment"># 并行作业数</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>特征提取相关参数</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">feats_type=raw        <span class="comment"># 特征类型(raw或fbank_pitch)</span></span><br><span class="line">audio_format=flac     <span class="comment"># 音频格式:wav,flac等</span></span><br><span class="line">fs=16k                <span class="comment"># 采样率</span></span><br><span class="line">min_wav_duration=0.1  <span class="comment"># 最短音频长度(秒)</span></span><br><span class="line">max_wav_duration=20   <span class="comment"># 最长音频长度(秒)</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>增强模型相关参数</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">enh_exp=             <span class="comment"># 增强实验目录路径</span></span><br><span class="line">enh_tag=             <span class="comment"># 增强模型训练结果目录的后缀</span></span><br><span class="line">enh_config=          <span class="comment"># 增强模型训练配置</span></span><br><span class="line">enh_args=            <span class="comment"># 增强模型训练的额外参数</span></span><br><span class="line">ref_num=2            <span class="comment"># 参考信号数量(等于说话人数量)</span></span><br><span class="line">inf_num=             <span class="comment"># 模型输出的推理结果数量</span></span><br><span class="line">noise_type_num=1     <span class="comment"># 输入音频中的噪声类型数量</span></span><br><span class="line">dereverb_ref_num=1   <span class="comment"># 去混响参考信号数量</span></span><br><span class="line">is_tse_task=<span class="literal">false</span>    <span class="comment"># 是否为目标说话人提取任务</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>训练数据相关参数</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">use_dereverb_ref=<span class="literal">false</span>   <span class="comment"># 是否使用去混响参考信号</span></span><br><span class="line">use_noise_ref=<span class="literal">false</span>      <span class="comment"># 是否使用噪声参考信号</span></span><br><span class="line">variable_num_refs=<span class="literal">false</span>  <span class="comment"># 是否使用可变数量的参考信号</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>推理和评估相关参数</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">inference_args=<span class="string">"--normalize_output_wav true --output_format wav"</span>  <span class="comment"># 推理参数</span></span><br><span class="line">inference_model=valid.loss.ave.pth  <span class="comment"># 推理使用的模型文件</span></span><br><span class="line">scoring_protocol=<span class="string">"STOI SDR SAR SIR SI_SNR"</span>  <span class="comment"># 评分指标</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="各Stage功能详细分析"><a href="#各Stage功能详细分析" class="headerlink" title="各Stage功能详细分析"></a>各Stage功能详细分析</h3><h4 id="Stage-1-数据准备"><a href="#Stage-1-数据准备" class="headerlink" title="Stage 1: 数据准备"></a>Stage 1: 数据准备</h4><ul>
<li><strong>功能</strong>：准备训练、验证和测试数据集</li>
<li><strong>执行</strong>：调用local/data.sh脚本处理数据</li>
<li><strong>关键代码</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="variable">${stage}</span> -le 1 ] &amp;&amp; [ <span class="variable">${stop_stage}</span> -ge 1 ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">log</span> <span class="string">"Stage 1: Data preparation for data/<span class="variable">${train_set}</span>, data/<span class="variable">${valid_set}</span>, etc."</span></span><br><span class="line">    <span class="comment"># [Task dependent] 需要为新语料库创建data.sh</span></span><br><span class="line">    <span class="built_in">local</span>/data.sh <span class="variable">${local_data_opts}</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></li>
<li><strong>重要说明</strong>：<ul>
<li>这个阶段是任务相关的，需要根据具体的语料库创建相应的data.sh脚本</li>
<li>local_data_opts参数可以传递给data.sh进行数据处理的定制</li>
</ul>
</li>
<li><strong>运行产出</strong>：<ul>
<li>在 <code>data/${train_set}</code>, <code>data/${valid_set}</code> 等目录下生成：<ul>
<li>wav.scp：音频文件路径映射</li>
<li>utt2spk：话语到说话人映射</li>
<li>spk2utt：说话人到话语映射</li>
<li>mix.scp：混合音频文件列表</li>
<li>ref.scp：参考音频文件列表</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>注：笔者一开始在找了好久<code>data.sh</code>在哪里，后面发现在具体的数据集中(详见上文训练任务流程)</p>
<h4 id="Stage-2-速度扰动"><a href="#Stage-2-速度扰动" class="headerlink" title="Stage 2: 速度扰动"></a>Stage 2: 速度扰动</h4><ul>
<li><strong>功能</strong>：对训练数据进行速度扰动增强</li>
<li><strong>条件</strong>：仅在设置了speed_perturb_factors且不使用去混响参考时执行</li>
<li><strong>处理</strong>：对音频进行不同速度的扰动，生成增强数据</li>
<li><strong>运行产出</strong>：<ul>
<li>在 <code>data/${train_set}_sp</code> 目录下生成：<ul>
<li>扰动后的音频文件和对应的配置文件</li>
<li>更新的 wav.scp, utt2spk, spk2utt 等文件</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Stage-3-音频格式化"><a href="#Stage-3-音频格式化" class="headerlink" title="Stage 3: 音频格式化"></a>Stage 3: 音频格式化</h4><ul>
<li><strong>功能</strong>：统一处理音频格式</li>
<li><strong>关键代码</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 格式化wav.scp文件</span></span><br><span class="line">scripts/audio/format_wav_scp.sh --nj <span class="string">"<span class="variable">${nj}</span>"</span> --cmd <span class="string">"<span class="variable">${train_cmd}</span>"</span> \</span><br><span class="line">    --out-filename <span class="string">"<span class="variable">${spk}</span>.scp"</span> \</span><br><span class="line">    --audio-format <span class="string">"<span class="variable">${audio_format}</span>"</span> --fs <span class="string">"<span class="variable">${fs}</span>"</span> <span class="variable">${_opts}</span> \</span><br><span class="line">    <span class="string">"data/<span class="variable">${dset}</span>/<span class="variable">${spk}</span>.scp"</span> <span class="string">"<span class="variable">${data_feats}</span><span class="variable">${_suf}</span>/<span class="variable">${dset}</span>"</span></span><br></pre></td></tr></table></figure></li>
<li><strong>处理步骤</strong>：<ol>
<li>重新创建”wav.scp”文件</li>
<li>统一音频格式和采样率</li>
<li>处理多说话人的情况</li>
<li>支持segments文件的分割处理</li>
</ol>
</li>
<li><strong>运行产出</strong>：<ul>
<li>在 <code>${data_feats}/${dset}</code> 目录下：<ul>
<li>统一格式后的音频文件</li>
<li>更新的 wav.scp 文件</li>
<li>各说话人的 .scp 文件</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Stage-4-数据筛选"><a href="#Stage-4-数据筛选" class="headerlink" title="Stage 4: 数据筛选"></a>Stage 4: 数据筛选</h4><ul>
<li><strong>功能</strong>：移除不符合长度要求的音频数据</li>
<li><strong>关键代码</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算最小和最大长度（样本数）</span></span><br><span class="line">_fs=$(python3 -c <span class="string">"import humanfriendly as h;print(h.parse_size('<span class="variable">${fs}</span>'))"</span>)</span><br><span class="line">_min_length=$(python3 -c <span class="string">"print(int(<span class="variable">${min_wav_duration}</span> * <span class="variable">${_fs}</span>))"</span>)</span><br><span class="line">_max_length=$(python3 -c <span class="string">"print(int(<span class="variable">${max_wav_duration}</span> * <span class="variable">${_fs}</span>))"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据长度筛选数据</span></span><br><span class="line">&lt;<span class="string">"<span class="variable">${data_feats}</span>/org/<span class="variable">${dset}</span>/utt2num_samples"</span> \</span><br><span class="line">    awk -v min_length=<span class="string">"<span class="variable">${_min_length}</span>"</span> -v max_length=<span class="string">"<span class="variable">${_max_length}</span>"</span> \</span><br><span class="line">    <span class="string">'{ if ($2 &gt; min_length &amp;&amp; $2 &lt; max_length ) print $0; }'</span> \</span><br><span class="line">    &gt;<span class="string">"<span class="variable">${data_feats}</span>/<span class="variable">${dset}</span>/utt2num_samples"</span></span><br></pre></td></tr></table></figure></li>
<li><strong>处理步骤</strong>：<ol>
<li>将时间长度转换为样本数</li>
<li>根据样本数筛选音频</li>
<li>更新相关的scp文件</li>
</ol>
</li>
<li><strong>运行产出</strong>：<ul>
<li>在 <code>${data_feats}/${dset}</code> 目录下：<ul>
<li>筛选后的 utt2num_samples 文件</li>
<li>更新后的 wav.scp, spk.scp 等文件</li>
<li>移除不符合长度要求的音频条目</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Stage-5-统计收集"><a href="#Stage-5-统计收集" class="headerlink" title="Stage 5: 统计收集"></a>Stage 5: 统计收集</h4><ul>
<li><strong>功能</strong>：收集训练所需的统计信息</li>
<li><strong>关键代码</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">${python}</span> -m <span class="variable">${train_module}</span> \</span><br><span class="line">    --collect_stats <span class="literal">true</span> \</span><br><span class="line">    <span class="variable">${_train_data_param}</span> \</span><br><span class="line">    <span class="variable">${_valid_data_param}</span> \</span><br><span class="line">    --train_shape_file <span class="string">"<span class="variable">${_logdir}</span>/train.JOB.scp"</span> \</span><br><span class="line">    --valid_shape_file <span class="string">"<span class="variable">${_logdir}</span>/valid.JOB.scp"</span> \</span><br><span class="line">    --output_dir <span class="string">"<span class="variable">${_logdir}</span>/stats.JOB"</span></span><br></pre></td></tr></table></figure></li>
<li><strong>处理步骤</strong>：<ol>
<li>收集训练和验证数据的统计信息</li>
<li>生成shape文件</li>
<li>聚合统计信息</li>
</ol>
</li>
<li><strong>运行产出</strong>：<ul>
<li>在 <code>${_logdir}</code> 目录下：<ul>
<li>stats.JOB 目录：包含统计信息</li>
<li>train.JOB.scp：训练数据shape信息</li>
<li>valid.JOB.scp：验证数据shape信息</li>
<li>global_stats：全局统计信息</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Stage-6-模型训练"><a href="#Stage-6-模型训练" class="headerlink" title="Stage 6: 模型训练"></a>Stage 6: 模型训练</h4><ul>
<li><strong>功能</strong>：执行增强模型的训练</li>
<li><strong>关键代码</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">${python}</span> -m <span class="variable">${train_module}</span> \</span><br><span class="line">    <span class="variable">${_train_data_param}</span> \</span><br><span class="line">    <span class="variable">${_valid_data_param}</span> \</span><br><span class="line">    <span class="variable">${_train_shape_param}</span> \</span><br><span class="line">    <span class="variable">${_valid_shape_param}</span> \</span><br><span class="line">    <span class="variable">${_fold_length_param}</span> \</span><br><span class="line">    --resume <span class="literal">true</span> \</span><br><span class="line">    --output_dir <span class="string">"<span class="variable">${enh_exp}</span>"</span> \</span><br><span class="line">    <span class="variable">${init_param:+--init_param $init_param}</span> \</span><br><span class="line">    <span class="variable">${_opts}</span> <span class="variable">${enh_args}</span></span><br></pre></td></tr></table></figure></li>
<li><strong>处理步骤</strong>：<ol>
<li>设置训练数据和验证数据</li>
<li>配置训练参数</li>
<li>支持断点续训</li>
<li>可选预训练模型初始化</li>
</ol>
</li>
<li><strong>运行产出</strong>：<ul>
<li>在 <code>${enh_exp}</code> 目录下：<ul>
<li>config.yaml：模型配置文件</li>
<li>模型检查点文件（*.pth）</li>
<li>trainer.log：训练日志</li>
<li>验证结果和曲线图表</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Stage-7-推理处理"><a href="#Stage-7-推理处理" class="headerlink" title="Stage 7: 推理处理"></a>Stage 7: 推理处理</h4><ul>
<li><strong>功能</strong>：使用训练好的模型进行音频增强</li>
<li><strong>关键代码</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">${python}</span> -m <span class="variable">${infer_module}</span> \</span><br><span class="line">    --ngpu <span class="string">"<span class="variable">${_ngpu}</span>"</span> \</span><br><span class="line">    --fs <span class="string">"<span class="variable">${fs}</span>"</span> \</span><br><span class="line">    <span class="variable">${_data_param}</span> \</span><br><span class="line">    --key_file <span class="string">"<span class="variable">${_logdir}</span>"</span>/keys.JOB.scp \</span><br><span class="line">    --train_config <span class="string">"<span class="variable">${enh_exp}</span>"</span>/config.yaml \</span><br><span class="line">    --model_file <span class="string">"<span class="variable">${enh_exp}</span>"</span>/<span class="string">"<span class="variable">${inference_model}</span>"</span> \</span><br><span class="line">    --output_dir <span class="string">"<span class="variable">${_logdir}</span>"</span>/output.JOB</span><br></pre></td></tr></table></figure></li>
<li><strong>处理步骤</strong>：<ol>
<li>加载训练好的模型</li>
<li>对测试集进行推理</li>
<li>生成增强后的音频</li>
<li>支持GPU推理</li>
</ol>
</li>
<li><strong>运行产出</strong>：<ul>
<li>在 <code>${_logdir}/output.JOB</code> 目录下：<ul>
<li>enhanced.wav：增强后的音频文件</li>
<li>keys.JOB.scp：处理的音频键值对</li>
<li>推理日志和结果文件</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Stage-8-评分"><a href="#Stage-8-评分" class="headerlink" title="Stage 8: 评分"></a>Stage 8: 评分</h4><ul>
<li><strong>功能</strong>：评估增强效果</li>
<li><strong>关键代码</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">${python}</span> -m espnet2.bin.enh_scoring \</span><br><span class="line">    --key_file <span class="string">"<span class="variable">${_logdir}</span>"</span>/keys.JOB.scp \</span><br><span class="line">    --output_dir <span class="string">"<span class="variable">${_logdir}</span>"</span>/output.JOB \</span><br><span class="line">    <span class="variable">${_ref_scp}</span> \</span><br><span class="line">    <span class="variable">${_inf_scp}</span> \</span><br><span class="line">    --ref_channel <span class="variable">${ref_channel}</span> \</span><br><span class="line">    --flexible_numspk <span class="variable">${flexible_numspk}</span></span><br></pre></td></tr></table></figure></li>
<li><strong>评估指标</strong>：<ul>
<li>STOI: 语音可懂度</li>
<li>SDR: 信号失真比</li>
<li>SAR: 伪影比</li>
<li>SIR: 干扰比</li>
<li>SI_SNR: 尺度不变信噪比</li>
</ul>
</li>
<li><strong>运行产出</strong>：<ul>
<li>在 <code>${_logdir}/output.JOB</code> 目录下：<ul>
<li>scoring.txt：包含各项评分指标</li>
<li>score_stats：详细的评分统计</li>
<li>各指标的得分分布图</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Stage-9-10-ASR评估"><a href="#Stage-9-10-ASR评估" class="headerlink" title="Stage 9-10: ASR评估"></a>Stage 9-10: ASR评估</h4><ul>
<li><strong>功能</strong>：使用ASR模型评估增强效果</li>
<li><strong>关键代码</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">${python}</span> -m espnet2.bin.asr_inference \</span><br><span class="line">    --ngpu <span class="string">"<span class="variable">${_ngpu}</span>"</span> \</span><br><span class="line">    --data_path_and_name_and_type <span class="string">"<span class="variable">${_ddir}</span>/wav.scp,speech,<span class="variable">${_type}</span>"</span> \</span><br><span class="line">    --key_file <span class="string">"<span class="variable">${_logdir}</span>"</span>/keys.JOB.scp \</span><br><span class="line">    --asr_train_config <span class="string">"<span class="variable">${asr_exp}</span>"</span>/config.yaml \</span><br><span class="line">    --asr_model_file <span class="string">"<span class="variable">${asr_exp}</span>"</span>/<span class="string">"<span class="variable">${inference_asr_model}</span>"</span> \</span><br><span class="line">    --output_dir <span class="string">"<span class="variable">${_logdir}</span>"</span>/output.JOB</span><br></pre></td></tr></table></figure></li>
<li><strong>处理步骤</strong>：<ol>
<li>使用ASR模型解码增强后的音频</li>
<li>计算字错误率(CER)或词错误率(WER)</li>
<li>生成评估报告</li>
</ol>
</li>
<li><strong>运行产出</strong>：<ul>
<li>在 <code>${_logdir}/output.JOB</code> 目录下：<ul>
<li>asr_inference.txt：ASR解码结果</li>
<li>text：识别的文本结果</li>
<li>wer.txt/cer.txt：错误率统计</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Stage-11-模型打包"><a href="#Stage-11-模型打包" class="headerlink" title="Stage 11: 模型打包"></a>Stage 11: 模型打包</h4><ul>
<li><strong>功能</strong>：将训练好的模型打包</li>
<li><strong>处理</strong>：<ul>
<li>打包模型文件</li>
<li>打包配置信息</li>
<li>生成发布包</li>
</ul>
</li>
<li><strong>运行产出</strong>：<ul>
<li>在 <code>${enh_exp}/pack</code> 目录下：<ul>
<li>model.zip：打包的模型文件</li>
<li>config.yaml：配置文件副本</li>
<li>README.md：模型说明文档</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Stage-12-上传模型"><a href="#Stage-12-上传模型" class="headerlink" title="Stage 12: 上传模型"></a>Stage 12: 上传模型</h4><ul>
<li><strong>功能</strong>：将模型上传到HuggingFace</li>
<li><strong>条件</strong>：当skip_upload_hf=false时执行</li>
<li><strong>处理</strong>：<ul>
<li>准备上传文件</li>
<li>配置HuggingFace仓库</li>
<li>上传模型</li>
</ul>
</li>
<li><strong>运行产出</strong>：<ul>
<li>在 HuggingFace仓库中：<ul>
<li>上传的模型文件和配置</li>
<li>模型卡片（model card）</li>
<li>示例代码和使用说明</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>enh1.sh是一个完整的语音增强处理流程脚本，包含了从数据准备到模型训练、评估的全过程。通过合理配置参数，可以灵活控制处理流程的各个环节。使用时需要特别注意：</p>
<ol>
<li>必须提供训练集、验证集和测试集的名称</li>
<li>根据需求合理设置GPU数量和并行作业数</li>
<li>可以通过stage和stop_stage控制执行流程</li>
<li>评估阶段提供了多种评估方式，包括客观指标和ASR评估</li>
</ol>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>AI辅助</tag>
        <tag>语音增强</tag>
        <tag>技术分析</tag>
        <tag>espnet</tag>
      </tags>
  </entry>
  <entry>
    <title>计网-物理层</title>
    <url>/2025/02/24/%E8%AE%A1%E7%BD%91-%E7%89%A9%E7%90%86%E5%B1%82/</url>
    <content><![CDATA[<p>物理层是计算机网络的最底层，主要负责数据的物理传输。</p>
<p>物理层为数据链路层提供服务，使数据链路层只需要考虑如何封装数据链路层协议数据单元（PDU），而不需要考虑数据是如何传输的。<br><span id="more"></span></p>
<p>注：有关计算机网络的相关概论知识，可参考以下：</p>
<ul>
<li><a href="https://blog.csdn.net/qq_46331050/article/details/120118138?spm=1001.2014.3001.5501">计算机网络概述</a></li>
</ul>
<h2 id="计算机网络基本重要概念"><a href="#计算机网络基本重要概念" class="headerlink" title="计算机网络基本重要概念"></a>计算机网络基本重要概念</h2><ul>
<li>因特网的组成：<ul>
<li>边缘部分： 由所有连接在因特网上的主机组成。</li>
<li>核心部分： 由大量网络和连接这些网络的路由器组成。</li>
</ul>
</li>
<li>路由器： 连接两个或多个网络的设备，负责在多个网络之间转发数据包。</li>
<li>交换方式：<ul>
<li>电路交换： 在数据传输之前，需要先建立一条专用的物理连接，数据传输过程中，这条连接一直存在。</li>
<li>报文交换： 不需要建立连接，数据传输过程中，不需要建立连接。</li>
<li>分组交换： 将数据分成多个小数据包，每个数据包独立传输，数据传输过程中，不需要建立连接。</li>
</ul>
</li>
<li>协议： 通信双方必须遵循的规则，包括：<ul>
<li>语法：数据与控制信息的结构或格式</li>
<li>语义：需要发出何种控制信息，完成何种动作以及做出何种响应</li>
<li>同步：事件实现顺序的详细说明</li>
</ul>
</li>
<li>服务： 在协议的控制下，两个对等实体间的通信使得本层能够向上一层提供服务，而与下层无关。</li>
<li>接口： 上层使用下层服务的入口，下层为上层提供服务的出口。</li>
<li>实体： 表示任何可发送或接收信息的硬件或软件进程。</li>
<li>服务访问点： 在同一系统中相邻两层的实体交换信息的逻辑接口，称为服务访问点SAP。<ul>
<li>数据链路层： 数据链路层SAP称为帧的“头”和“尾”</li>
<li>网络层： 网络层SAP称为IP地址<ul>
<li>IP地址： 网络层地址，用于标识网络中的一个节点</li>
</ul>
</li>
<li>传输层： 传输层SAP称为端口<ul>
<li>端口： 传输层地址，用于标识一个进程</li>
</ul>
</li>
</ul>
</li>
<li>服务原语：<ul>
<li>PDU： 协议数据单元，对等实体之间传送的数据包称为协议数据单元。</li>
<li>SDU： 服务数据单元，层与层之间传送的数据包称为服务数据单元。</li>
</ul>
</li>
<li>连接唯一性：四元组（源IP地址，源端口，目的IP地址，目的端口）唯一标识一个连接</li>
</ul>
<h2 id="一、物理层的基本概念"><a href="#一、物理层的基本概念" class="headerlink" title="一、物理层的基本概念"></a>一、物理层的基本概念</h2><h3 id="1-1-物理层的功能"><a href="#1-1-物理层的功能" class="headerlink" title="1.1 物理层的功能"></a>1.1 物理层的功能</h3><ul>
<li>定义物理接口特性<ul>
<li>机械特性： 接口的形状、尺寸、引脚数目和排列情况</li>
<li>电气特性： 接口的电压范围、电流强度、阻抗匹配、传输速率等</li>
<li>功能特性： 接口的信号线功能</li>
<li>规程特性： 接口的规程</li>
</ul>
</li>
<li>定义传输介质的特性</li>
<li>定义数据传输速率</li>
<li>比特同步和时钟同步</li>
<li>比特编码方式的定义</li>
</ul>
<h3 id="1-2-数据通信的基本概念"><a href="#1-2-数据通信的基本概念" class="headerlink" title="1.2 数据通信的基本概念"></a>1.2 数据通信的基本概念</h3><ul>
<li>数据（Data）：传送信息的实体</li>
<li>信号（Signal）：数据的电气或电磁表现</li>
<li>模拟信号：连续的信号</li>
<li>数字信号：离散的信号</li>
</ul>
<h2 id="二、传输介质"><a href="#二、传输介质" class="headerlink" title="二、传输介质"></a>二、传输介质</h2><h3 id="2-1-导向传输介质"><a href="#2-1-导向传输介质" class="headerlink" title="2.1 导向传输介质"></a>2.1 导向传输介质</h3><ol>
<li><p>双绞线</p>
<ul>
<li>非屏蔽双绞线（UTP）</li>
<li>屏蔽双绞线（STP）</li>
<li>常用于以太网</li>
</ul>
</li>
<li><p>同轴电缆</p>
<ul>
<li>基带同轴电缆</li>
<li>宽带同轴电缆</li>
<li>抗干扰能力强</li>
</ul>
</li>
<li><p>光纤</p>
<ul>
<li>单模光纤</li>
<li>多模光纤</li>
<li>传输距离远，带宽大</li>
</ul>
</li>
</ol>
<h3 id="2-2-非导向传输介质"><a href="#2-2-非导向传输介质" class="headerlink" title="2.2 非导向传输介质"></a>2.2 非导向传输介质</h3><ul>
<li>无线电波</li>
<li>微波</li>
<li>红外线</li>
<li>激光</li>
</ul>
<h2 id="三、传输方式"><a href="#三、传输方式" class="headerlink" title="三、传输方式"></a>三、传输方式</h2><h3 id="3-1-串行传输与并行传输"><a href="#3-1-串行传输与并行传输" class="headerlink" title="3.1 串行传输与并行传输"></a>3.1 串行传输与并行传输</h3><ul>
<li>串行传输： 数据逐位按顺序依次传输</li>
<li>并行传输： 数据同时多位按顺序依次传输</li>
</ul>
<h3 id="3-2-同步传输与异步传输"><a href="#3-2-同步传输与异步传输" class="headerlink" title="3.2 同步传输与异步传输"></a>3.2 同步传输与异步传输</h3><ul>
<li>同步传输： 数据块按固定长度依次传输<ul>
<li>外同步： 添加单独时钟信号线</li>
<li>内同步： 数据中包含时钟信息</li>
</ul>
</li>
<li>异步传输： 数据块按不定长度依次传输</li>
</ul>
<h3 id="3-3-单工、半双工与全双工"><a href="#3-3-单工、半双工与全双工" class="headerlink" title="3.3 单工、半双工与全双工"></a>3.3 单工、半双工与全双工</h3><ul>
<li>单工： 单向传输 无线电广播</li>
<li>半双工： 双向交替传输 对讲机</li>
<li>全双工： 双向同时传输 电话</li>
</ul>
<h2 id="四、信道与信道容量"><a href="#四、信道与信道容量" class="headerlink" title="四、信道与信道容量"></a>四、信道与信道容量</h2><h3 id="4-1-信道的基本概念"><a href="#4-1-信道的基本概念" class="headerlink" title="4.1 信道的基本概念"></a>4.1 信道的基本概念</h3><ul>
<li>单工通信：单向传输</li>
<li>半双工通信：双向交替传输</li>
<li>全双工通信：双向同时传输</li>
</ul>
<h3 id="4-2-信道容量"><a href="#4-2-信道容量" class="headerlink" title="4.2 信道容量"></a>4.2 信道容量</h3><ul>
<li>奈奎斯特定理：理想低通信道的最高码元速率<ul>
<li>公式：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.546ex;" xmlns="http://www.w3.org/2000/svg" width="17.31ex" height="2.116ex" role="img" focusable="false" viewBox="0 -694 7650.8 935.4"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(878,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1407,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2519.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(3574.9,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(4074.9,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="msub" transform="translate(5000.6,0)"><g data-mml-node="mi"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mn" transform="translate(1311,-241.4) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(6715.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(6881.8,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g></g></g></svg></mjx-container></li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.717ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 759 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g></g></g></svg></mjx-container>：带宽</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.74ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 769 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g></g></g></svg></mjx-container>：电平数</li>
</ul>
</li>
<li>香农定理：信道的最大数据传输速率<ul>
<li>公式：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="20.967ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9267.2 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mo" transform="translate(1037.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2093.6,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="msub" transform="translate(3019.2,0)"><g data-mml-node="mi"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mn" transform="translate(1311,-241.4) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(4733.8,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(4733.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(5122.8,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(5845,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(6845.2,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(7490.2,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="mi" transform="translate(7990.2,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(8878.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.717ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 759 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g></g></g></svg></mjx-container>：带宽</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.6ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2033 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(645,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="mi" transform="translate(1145,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container>：信噪比</li>
</ul>
</li>
<li>信噪比与带宽的关系</li>
</ul>
<h2 id="五、数字传输系统"><a href="#五、数字传输系统" class="headerlink" title="五、数字传输系统"></a>五、数字传输系统</h2><h3 id="5-1-编码与调制"><a href="#5-1-编码与调制" class="headerlink" title="5.1 编码与调制"></a>5.1 编码与调制</h3><ol>
<li><p>基带传输</p>
<ul>
<li>不归零编码（NRZ）：存在同步问题<ul>
<li>正电平表示1，负电平表示0</li>
</ul>
</li>
<li>归零编码（RZ）：自同步，编码效率低</li>
<li>曼彻斯特编码<ul>
<li>每个码元中间有跳变，负跳变表示1，正跳变表示0</li>
</ul>
</li>
<li>差分曼彻斯特编码</li>
</ul>
</li>
<li><p>带通传输</p>
<ul>
<li>调幅（AM）</li>
<li>调频（FM）</li>
<li>调相（PM）</li>
</ul>
</li>
</ol>
<h3 id="5-2-多路复用技术"><a href="#5-2-多路复用技术" class="headerlink" title="5.2 多路复用技术"></a>5.2 多路复用技术</h3><ul>
<li>频分复用（FDM）</li>
<li>时分复用（TDM）</li>
<li>波分复用（WDM）</li>
<li>码分复用（CDM）</li>
</ul>
<h2 id="六、物理层设备"><a href="#六、物理层设备" class="headerlink" title="六、物理层设备"></a>六、物理层设备</h2><h3 id="6-1-中继器"><a href="#6-1-中继器" class="headerlink" title="6.1 中继器"></a>6.1 中继器</h3><ul>
<li>功能：放大信号</li>
<li>特点：不能连接不同类型网络</li>
<li>5-4-3规则</li>
</ul>
<h3 id="6-2-集线器"><a href="#6-2-集线器" class="headerlink" title="6.2 集线器"></a>6.2 集线器</h3><ul>
<li>功能：多端口中继器</li>
<li>特点：共享带宽，冲突域</li>
<li>工作方式：广播方式</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>AI辅助</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>移动端人工智能技术</title>
    <url>/2025/02/23/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<p>本文在deepseek辅助下帮助笔者理解移动端人工智能的知识蒸馏（Knowledge Distillation）、量化（Quantization）和剪枝（Pruning）三种模型压缩技术。<br><span id="more"></span></p>
<h3 id="1-知识蒸馏（Knowledge-Dististillation）"><a href="#1-知识蒸馏（Knowledge-Dististillation）" class="headerlink" title="1. 知识蒸馏（Knowledge Dististillation）"></a><strong>1. 知识蒸馏（Knowledge Dististillation）</strong></h3><h4 id="核心原理"><a href="#核心原理" class="headerlink" title="核心原理"></a><strong>核心原理</strong></h4><p>通过训练一个轻量化的“学生模型”（Student Model），模仿复杂“教师模型”（Teacher Model）的输出行为，从而将教师模型的知识迁移到学生模型中。</p>
<ul>
<li><strong>知识来源</strong>：教师模型的输出概率分布（软标签）、中间层特征或注意力机制。</li>
<li><strong>目标</strong>：学生模型在保持小体积的同时，达到接近教师模型的性能。</li>
</ul>
<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a><strong>示例</strong></h4><p><strong>场景</strong>：图像分类任务（如ImageNet数据集）  </p>
<ul>
<li><strong>教师模型</strong>：大型模型（如ResNet-50，准确率76%）。</li>
<li><strong>学生模型</strong>：轻量模型（如MobileNetV3，准确率直接训练仅70%）。  </li>
<li><strong>蒸馏过程</strong>：  <ol>
<li>教师模型对训练数据生成“软标签”（Soft Labels，即各类别概率分布，如<code>[0.7, 0.2, 0.1]</code>）。  </li>
<li>学生模型同时学习真实标签（硬标签）和软标签。<br>结合硬标签损失和软标签的KL散度损失函数：<script type="math/tex; mode=display">
L = \alpha L_{CE} + (1 - \alpha) L_{KL}</script>其中，<script type="math/tex">L_{CE}</script>为交叉熵损失，<script type="math/tex">L_{KL}</script>为KL散度损失。</li>
</ol>
</li>
</ul>
<h4 id="深入思考"><a href="#深入思考" class="headerlink" title="深入思考"></a>深入思考</h4><p>1.<strong>为什么学生模型参数更少却能接近教师性能？</strong></p>
<p>类比于二级结论，学生模型具有教师模型的先验知识（概率分布），而不需要从底层开始全部学习。我们称之为<strong>决策边界抽象能力</strong>。</p>
<p>信息论角度：将教师模型中“有效信息”（决策边界、特征相关性）编码到学生模型的参数中，而非复制所有参数。</p>
<p>2.<strong>软标签概率分布如何生成？</strong></p>
<p>核心方法：温度缩放（Temperature Scaling）<br>软标签并非直接使用教师模型的原始输出，而是通过引入温度参数（Temperature, T）对概率分布进行平滑处理，以传递类别间的关系信息。</p>
<p>数学公式：</p>
<script type="math/tex; mode=display">
p_i = \frac{e^{\frac{z_i}{T}}}{\sum_{j=1}^{C} e^{\frac{z_j}{T}}}</script><p>其中，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.792ex" height="1.357ex" role="img" focusable="false" viewBox="0 -442 792 599.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(498,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>是教师模型在类别<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container>的原始输出，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.593ex" height="1.532ex" role="img" focusable="false" viewBox="0 -677 704 677"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></svg></mjx-container>是温度参数，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.719ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 760 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g></g></g></svg></mjx-container>是类别总数。</p>
<p>T的作用：</p>
<ul>
<li>当 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="5.741ex" height="1.717ex" role="img" focusable="false" viewBox="0 -677 2537.6 759"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mo" transform="translate(981.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(2037.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container> 时，软标签等同于硬标签。</li>
<li>当 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.09ex;" xmlns="http://www.w3.org/2000/svg" width="5.741ex" height="1.622ex" role="img" focusable="false" viewBox="0 -677 2537.6 717"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mo" transform="translate(981.8,0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="mn" transform="translate(2037.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container> 时，概率分布更平滑，类别间关系信息更丰富。</li>
<li>当 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="7.375ex" height="1.557ex" role="img" focusable="false" viewBox="0 -677 3259.6 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mo" transform="translate(981.8,0)"><path data-c="2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(2259.6,0)"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path></g></g></g></svg></mjx-container> 时，概率分布趋近于均匀分布。</li>
</ul>
<p>3.<strong>为什么不在训练教师模型时使用软标签？</strong></p>
<p>根本原因：教师模型的训练目标不同</p>
<ul>
<li>教师模型的使命：追求最高精度，而非传递知识<ul>
<li>教师模型需尽可能拟合数据中的细节，硬标签（明确答案）是更直接的监督信号。</li>
<li>软标签会引入不必要的“不确定性”，降低模型对正确类别的置信度。</li>
</ul>
</li>
<li>软标签的来源矛盾：<ul>
<li>知识蒸馏中，软标签由更强大的教师模型生成（例如ResNet-50教MobileNet）。</li>
<li>若在训练教师模型时使用软标签，需要另一个更强的模型生成软标签，但这会导致无限递归问题（谁来生成这个更强的模型的软标签？）</li>
</ul>
</li>
</ul>
<p>4.<strong>知识蒸馏的局限性</strong></p>
<ul>
<li>需要高质量的教师模型：教师模型需要足够大，才能提供高质量的软标签。</li>
<li>需要大量计算资源：教师模型需要大量计算资源，才能生成高质量的软标签。</li>
<li>需要大量数据：教师模型需要大量数据，才能生成高质量的软标签。</li>
</ul>
<hr>
<h3 id="2-量化（Quantization）"><a href="#2-量化（Quantization）" class="headerlink" title="2. 量化（Quantization）"></a><strong>2. 量化（Quantization）</strong></h3><h4 id="核心原理-1"><a href="#核心原理-1" class="headerlink" title="核心原理"></a><strong>核心原理</strong></h4><p>将模型参数（权重）和激活值从高精度浮点数（如32位）转换为低精度数值（如8位整数），减少模型体积和计算资源消耗。  </p>
<ul>
<li><strong>类型</strong>：  <ul>
<li><strong>训练后量化（Post-training Quantization）</strong>：直接对训练好的模型进行量化。  </li>
<li><strong>量化感知训练（Quantization-aware Training）</strong>：在训练过程中模拟量化误差，提升最终量化模型的精度。</li>
</ul>
</li>
</ul>
<h4 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a><strong>示例</strong></h4><p><strong>场景</strong>：手机端语音识别模型  </p>
<ul>
<li><strong>原始模型</strong>：基于LSTM的语音识别模型，使用FP32精度，大小120MB，延迟50ms。  </li>
<li><strong>量化步骤</strong>：  <ol>
<li>将权重和激活值从FP32量化为INT8（范围映射到-128~127）。  </li>
<li>引入反量化（Dequantization）层，在关键计算节点恢复精度。  </li>
</ol>
</li>
<li><strong>结果</strong>：模型大小缩减至30MB，延迟降至15ms，准确率损失小于1%。</li>
</ul>
<p>下面以Pytorch为例，展示训练后量化和量化感知训练的实现。</p>
<h5 id="训练后量化"><a href="#训练后量化" class="headerlink" title="训练后量化"></a>训练后量化</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.quantization</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> mobilenet_v2</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1: 加载预训练模型</span></span><br><span class="line">model = mobilenet_v2(pretrained=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2: 定义量化配置</span></span><br><span class="line">model.qconfig = torch.quantization.get_default_qconfig(<span class="string">'qnnpack'</span>)  <span class="comment"># 移动端优化配置</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3: 插入观察器（Observer）校准量化参数</span></span><br><span class="line">model_fp32_prepared = torch.quantization.prepare(model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 4: 用校准数据运行模型（此处用随机数据示例）</span></span><br><span class="line">input_fp32 = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)  <span class="comment"># 假设输入尺寸为224x224</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    model_fp32_prepared(input_fp32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 5: 转换为量化模型</span></span><br><span class="line">model_int8 = torch.quantization.convert(model_fp32_prepared)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存量化模型</span></span><br><span class="line">torch.save(model_int8.state_dict(), <span class="string">"mobilenet_v2_quantized.pth"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查模型大小</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"FP32模型大小:"</span>, os.path.getsize(<span class="string">"mobilenet_v2.pth"</span>)/<span class="number">1e6</span>, <span class="string">"MB"</span>)     <span class="comment"># 约14MB</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"INT8模型大小:"</span>, os.path.getsize(<span class="string">"mobilenet_v2_quantized.pth"</span>)/<span class="number">1e6</span>, <span class="string">"MB"</span>)  <span class="comment"># 约3.5MB</span></span><br></pre></td></tr></table></figure>
<h5 id="量化感知训练"><a href="#量化感知训练" class="headerlink" title="量化感知训练"></a>量化感知训练</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.quantization <span class="keyword">import</span> QuantStub, DeQuantStub</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1: 定义支持量化的模型结构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuantizableModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.quant = QuantStub()      <span class="comment"># 量化入口</span></span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dequant = DeQuantStub()  <span class="comment"># 反量化出口</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.quant(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.dequant(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2: 插入伪量化节点</span></span><br><span class="line">model = QuantizableModel()</span><br><span class="line">model.qconfig = torch.quantization.get_default_qat_qconfig(<span class="string">'qnnpack'</span>)</span><br><span class="line">model.train()  <span class="comment"># 切换到训练模式</span></span><br><span class="line">model_prepared = torch.quantization.prepare_qat(model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3: 正常训练流程（需使用FP32数据）</span></span><br><span class="line">optimizer = torch.optim.SGD(model_prepared.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> data, target <span class="keyword">in</span> train_loader:  <span class="comment"># 假设已有数据加载器</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model_prepared(data)</span><br><span class="line">        loss = nn.CrossEntropyLoss()(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 4: 转换为最终量化模型</span></span><br><span class="line">model_int8 = torch.quantization.convert(model_prepared)</span><br></pre></td></tr></table></figure>
<h4 id="深入思考-1"><a href="#深入思考-1" class="headerlink" title="深入思考"></a>深入思考</h4><p>手动实现量化计算：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 原始FP32计算</span></span><br><span class="line">W_fp32 = torch.tensor([<span class="number">2.5</span>, -<span class="number">1.3</span>, <span class="number">0.8</span>], dtype=torch.float32)</span><br><span class="line">x_fp32 = torch.tensor([<span class="number">0.4</span>, <span class="number">1.2</span>, -<span class="number">0.5</span>], dtype=torch.float32)</span><br><span class="line">y_fp32 = torch.dot(W_fp32, x_fp32)  <span class="comment"># 输出：2.5*0.4 + (-1.3)*1.2 + 0.8*(-0.5) = -1.56</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 量化到INT8（范围假设为[-5, 5]）</span></span><br><span class="line">scale_W = <span class="number">5</span> / <span class="number">127</span>  <span class="comment"># 对称量化，scale = max(abs(W)) / 127</span></span><br><span class="line">W_int8 = torch.clamp((W_fp32 / scale_W).<span class="built_in">round</span>(), <span class="built_in">min</span>=-<span class="number">128</span>, <span class="built_in">max</span>=<span class="number">127</span>).to(torch.int8)</span><br><span class="line">scale_x = <span class="number">5</span> / <span class="number">127</span></span><br><span class="line">x_int8 = torch.clamp((x_fp32 / scale_x).<span class="built_in">round</span>(), <span class="built_in">min</span>=-<span class="number">128</span>, <span class="built_in">max</span>=<span class="number">127</span>).to(torch.int8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 整数计算</span></span><br><span class="line">y_int32 = torch.dot(W_int8.<span class="built_in">float</span>(), x_int8.<span class="built_in">float</span>())  <span class="comment"># 转为float避免溢出</span></span><br><span class="line">y_dequant = y_int32 * (scale_W * scale_x)  <span class="comment"># 反量化</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"FP32结果:"</span>, y_fp32.item())        <span class="comment"># -1.56</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"量化结果:"</span>, y_dequant.item())     <span class="comment"># 约-1.55（存在微小误差）</span></span><br></pre></td></tr></table></figure>
<p>量化完整流程：</p>
<ul>
<li>准备阶段<ul>
<li>插入观察器到模型中，统计各层的权重和激活值分布。</li>
<li>代码操作：model_prepared = prepare(model)</li>
</ul>
</li>
<li>校准阶段<ul>
<li>用代表性数据运行模型，观察器记录各层的min/max值。</li>
<li>代码操作：model_prepared(input_data)</li>
</ul>
</li>
<li>转换阶段<ul>
<li>根据校准结果计算量化参数，替换浮点算子为量化算子。</li>
<li>代码操作：model_quantized = convert(model_prepared)</li>
</ul>
</li>
</ul>
<p><strong>核心公式</strong>：</p>
<ul>
<li>量化公式：<script type="math/tex">Q(x) = \text{clamp}\left(\text{round}\left(\frac{x}{\text{scale}} + \text{zero\_point}\right), \text{min}, \text{max}\right)</script><ul>
<li>clamp：将结果限制在min和max之间</li>
<li>round：四舍五入</li>
<li>zero_point：量化偏移量, 用于校准, 通常为0</li>
</ul>
</li>
<li>反量化公式：<script type="math/tex">x = \left(\text{Q}(x) - \text{zero\_point}\right) \times \text{scale}</script></li>
</ul>
<h4 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a><strong>实际应用</strong></h4><ul>
<li>TensorFlow Lite：默认支持训练后量化，可将目标检测模型（如SSD MobileNet）从16MB压缩到4MB。  </li>
<li>苹果Core ML：在iPhone上运行量化后的StyleGAN模型，实现实时人像风格迁移。</li>
</ul>
<hr>
<h3 id="3-剪枝（Pruning）"><a href="#3-剪枝（Pruning）" class="headerlink" title="3. 剪枝（Pruning）"></a><strong>3. 剪枝（Pruning）</strong></h3><h4 id="核心原理-2"><a href="#核心原理-2" class="headerlink" title="核心原理"></a><strong>核心原理</strong></h4><p>通过移除模型中不重要的参数（如接近零的权重）或结构（如冗余神经元），减少模型复杂度。  </p>
<ul>
<li><strong>类型</strong>：  <ul>
<li><strong>非结构化剪枝</strong>：删除单个权重（稀疏化）。  </li>
<li><strong>结构化剪枝</strong>：删除整层神经元或通道（更适合硬件加速）。</li>
</ul>
</li>
</ul>
<h4 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a><strong>示例</strong></h4><p><strong>场景</strong>：自然语言处理中的BERT模型压缩  </p>
<ul>
<li><strong>原始模型</strong>：BERT-base（1.1亿参数，模型大小400MB）。  </li>
<li><strong>剪枝过程</strong>：  <ol>
<li>在微调阶段，根据权重绝对值或梯度重要性评分，剪枝30%的注意力头。  </li>
<li>重新训练剩余参数以恢复精度。  </li>
</ol>
</li>
<li><strong>结果</strong>：模型大小减少至280MB，推理速度提升1.5倍，在GLUE基准上精度下降仅0.5%。</li>
</ul>
<p>以下是Pytorch实现剪枝的示例：</p>
<h5 id="非结构化剪枝"><a href="#非结构化剪枝" class="headerlink" title="非结构化剪枝"></a>非结构化剪枝</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.utils.prune <span class="keyword">as</span> prune</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义示例模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">3</span>)  <span class="comment"># 输入通道3，输出通道16</span></span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">16</span>*<span class="number">26</span>*<span class="number">26</span>, <span class="number">10</span>)  <span class="comment"># 假设输入图像尺寸为28x28</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = SimpleCNN()</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 剪枝步骤 ---</span></span><br><span class="line"><span class="comment"># Step 1: 选择剪枝目标（这里剪枝conv1层的权重）</span></span><br><span class="line">parameters_to_prune = [(model.conv1, <span class="string">'weight'</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2: 应用L1范数剪枝（剪去20%的权重）</span></span><br><span class="line">prune.global_unstructured(</span><br><span class="line">    parameters_to_prune,</span><br><span class="line">    pruning_method=prune.L1Unstructured,</span><br><span class="line">    amount=<span class="number">0.2</span>  <span class="comment"># 剪枝比例20%</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3: 查看剪枝效果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"剪枝后的权重稀疏度："</span>, </span><br><span class="line">      torch.<span class="built_in">sum</span>(model.conv1.weight == <span class="number">0</span>).item() / model.conv1.weight.nelement())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 4: 永久移除剪枝的权重（可选）</span></span><br><span class="line">prune.remove(model.conv1, <span class="string">'weight'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 5: 微调剪枝后的模型</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="keyword">for</span> data, target <span class="keyword">in</span> train_loader:  <span class="comment"># 假设已有数据加载器</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = nn.CrossEntropyLoss()(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>为什么用L1范数剪枝？</strong>：<br>L1范数具有自然的稀疏性特征，通过最小化L1范数，模型倾向于将一些权重推向0以实现稀疏化，并且计算简单。</p>
<h5 id="结构化剪枝"><a href="#结构化剪枝" class="headerlink" title="结构化剪枝"></a>结构化剪枝</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn.utils.prune <span class="keyword">import</span> ln_structured, remove_structured</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1: 剪枝整个通道（基于L2范数）</span></span><br><span class="line"><span class="comment"># 对conv1层的输出通道进行剪枝（移除20%的通道）</span></span><br><span class="line">prune.ln_structured(</span><br><span class="line">    model.conv1,</span><br><span class="line">    name=<span class="string">"weight"</span>,</span><br><span class="line">    amount=<span class="number">0.2</span>,</span><br><span class="line">    n=<span class="number">2</span>,  <span class="comment"># L2范数</span></span><br><span class="line">    dim=<span class="number">0</span>  <span class="comment"># 沿输出通道维度剪枝</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2: 查看通道剪枝后的权重形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"剪枝后的conv1.weight形状:"</span>, model.conv1.weight.shape)  </span><br><span class="line"><span class="comment"># 原始形状[16,3,3,3] → 剪枝后[13,3,3,3]（假设移除3个通道）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3: 永久应用剪枝</span></span><br><span class="line">remove_structured(model.conv1, <span class="string">'weight'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 4: 调整后续层（重要！结构化剪枝需适配网络结构）</span></span><br><span class="line"><span class="comment"># 原fc层输入维度为16*26*26，剪枝后变为13*26*26 → 需要重新定义</span></span><br><span class="line">model.fc = nn.Linear(<span class="number">13</span>*<span class="number">26</span>*<span class="number">26</span>, <span class="number">10</span>)  <span class="comment"># 修改输入维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 微调模型（同上）</span></span><br></pre></td></tr></table></figure>
<p><strong>为什么用L2范数剪枝？</strong>：</p>
<ul>
<li>避免极端值：均匀缩小</li>
<li>计算效率：L2范数计算复杂度较低</li>
</ul>
<h4 id="实际应用-1"><a href="#实际应用-1" class="headerlink" title="实际应用"></a><strong>实际应用</strong></h4><ul>
<li>NVIDIA的Nemo框架：对语音识别模型（如QuartzNet）进行结构化剪枝，GPU推理速度提升2倍。  </li>
<li>无人机避障算法：剪枝后的YOLOv5模型在边缘设备上实时检测障碍物，功耗降低40%。</li>
</ul>
<hr>
<h3 id="三者的对比与协同使用"><a href="#三者的对比与协同使用" class="headerlink" title="三者的对比与协同使用"></a><strong>三者的对比与协同使用</strong></h3><div class="table-container">
<table>
<thead>
<tr>
<th>技术</th>
<th>核心目标</th>
<th>优势</th>
<th>局限性</th>
<th>典型压缩率</th>
</tr>
</thead>
<tbody>
<tr>
<td>知识蒸馏</td>
<td>迁移知识到小模型</td>
<td>精度接近教师模型</td>
<td>依赖高质量教师模型</td>
<td>2-5倍</td>
</tr>
<tr>
<td>量化</td>
<td>降低数值精度</td>
<td>显著减少体积和计算开销</td>
<td>可能损失精度（需校准）</td>
<td>4倍+</td>
</tr>
<tr>
<td>剪枝</td>
<td>移除冗余参数或结构</td>
<td>提升推理速度，降低内存占用</td>
<td>可能破坏模型结构完整性</td>
<td>2-10倍</td>
</tr>
</tbody>
</table>
</div>
<p><strong>协同使用案例</strong>：<br>谷歌的MobileNetV4模型结合三者：  </p>
<ol>
<li>用知识蒸馏从EfficientNet迁移知识；  </li>
<li>对模型进行混合精度量化（部分层用INT8，关键层用FP16）；  </li>
<li>剪枝掉80%的冗余通道，最终模型体积减少6倍，速度提升3倍，精度仅下降2%。  </li>
</ol>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>知识蒸馏、量化和剪枝是移动端AI模型压缩的三大核心技术：  </p>
<ul>
<li><strong>知识蒸馏</strong>：通过“师生学习”传递知识，适合模型功能迁移；  </li>
<li><strong>量化</strong>：降低数值精度，直接压缩体积和加速计算；  </li>
<li><strong>剪枝</strong>：消除冗余参数，提升硬件执行效率。<br>实际应用中，三者常结合使用（如“蒸馏+量化+剪枝”流程），在保证精度的前提下，实现移动端AI模型的极致优化。</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>AI辅助</tag>
        <tag>端侧AI</tag>
      </tags>
  </entry>
  <entry>
    <title>常用网址(持续更新)</title>
    <url>/2025/02/21/%E5%B8%B8%E7%94%A8%E7%BD%91%E5%9D%80/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="90f5550756d2c341d01836eef78e75a2e2608e2fe9efa3622e6005f2502183e2">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-xray">
      <input class="hbe hbe-input-field hbe-input-field-xray" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-xray" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-xray">Hey, password is required here.</span>
      </label>
      <svg class="hbe hbe-graphic hbe-graphic-xray" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">
        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>
        <path d="M0,2.5c0,0,298.666,0,399.333,0C448.336,2.5,513.994,13,597,13c77.327,0,135-10.5,200.999-10.5c95.996,0,402.001,0,402.001,0"></path>
      </svg>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>学业规划</tag>
      </tags>
  </entry>
  <entry>
    <title>大二寒假小记</title>
    <url>/2025/02/16/Daily/%E5%A4%A7%E4%BA%8C%E5%AF%92%E5%81%87%E5%B0%8F%E8%AE%B0/</url>
    <content><![CDATA[<p>今天是寒假最后一天了，在此写下自己的第一篇博客，尽管寒假没怎么学习，但希望这篇小记作为新学期一个良好的开始！<br><span id="more"></span></p>
<h2 id="时间跨度"><a href="#时间跨度" class="headerlink" title="时间跨度"></a>时间跨度</h2><ul>
<li>学校寒假：2025.1.20 —— 2025.2.17</li>
<li>实际假期：2025.1.17 —— 2025.2.17</li>
<li>总计：31天</li>
</ul>
<h2 id="计划-vs-现实"><a href="#计划-vs-现实" class="headerlink" title="计划 vs 现实"></a>计划 vs 现实</h2><ol>
<li>旅游阶段（1.17 ~ 2.4）</li>
<li>学习阶段（2.5 ~ 2.16）<ul>
<li>espnet学习</li>
<li>TOEFL备考</li>
<li>驾照考试</li>
<li>个人博客搭建</li>
</ul>
</li>
</ol>
<p>理想很丰满，现实很……</p>
<p>当然这个寒假也不是什么都没有干，通过寒假前半段时间的完全放松，我彻底放下了一些感情上的羁绊，也逐渐思考发掘人生方向，将自己从低欲望的状态中解救出来，对心理学产生兴趣，重新发现存在主义的奥妙等等。后半段时间，每天被各种琐碎的事务占据，但也进行了一些不算完整的规划与思考。总体而言，从心理上在逐渐改进自己的认知。</p>
<h2 id="TimeLine"><a href="#TimeLine" class="headerlink" title="TimeLine"></a>TimeLine</h2><div class="table-container">
<table>
<thead>
<tr>
<th>日期</th>
<th>日程</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.17</td>
<td>考完</td>
</tr>
<tr>
<td>1.17 ~ 1.22</td>
<td>崇礼滑雪</td>
</tr>
<tr>
<td>1.23 ~ 1.26</td>
<td>长沙同学聚会</td>
</tr>
<tr>
<td>1.27 ~ 1.30</td>
<td>Kuala Lumpur</td>
</tr>
<tr>
<td>1.31 ~ 2.3</td>
<td>Langkawi</td>
</tr>
<tr>
<td>2.4</td>
<td>春节档电影大赏</td>
</tr>
<tr>
<td>2.5 ~ 2.15</td>
<td>科二科三，搭建个人博客</td>
</tr>
<tr>
<td>2.16</td>
<td>南京 -&gt; 上海</td>
</tr>
</tbody>
</table>
</div>
<p>除此之外</p>
<ul>
<li>更换新电脑<code>ThinkBook 14 G6+__</code><ul>
<li>处理器：Intel(R) Core(TM) Ultra 9 185H   2.30 GHz</li>
<li>机带 RAM：32.0 GB (31.6 GB 可用)</li>
<li>硬盘 1T</li>
<li>NVIDIA 4060 8G</li>
<li>最重要的是只有1.5kg啊！！！<br>注：当时换电脑为wsl的转移折腾了两三天，碰到了各种奇奇怪怪的问题，之后打算写一篇帖子记录下。</li>
</ul>
</li>
<li>换了新书包 <code>__LEVEL8 MOMENT__</code>  <ul>
<li>颜值超高！分区便捷</li>
<li>美中不足的是1.35kg略沉，于是包+电脑与之前相比重量几乎没什么变化(doge)</li>
</ul>
</li>
<li>拔牙<ul>
<li>关于我三年前拔了一颗智齿现在又长出来三颗忍痛拔掉一颗的故事</li>
</ul>
</li>
</ul>
<h3 id="滑雪"><a href="#滑雪" class="headerlink" title="滑雪"></a>滑雪</h3><p>在崇礼云顶练习单板滑雪4天，从小白到勉强可以在中级道上换刃</p>
<h3 id="同学聚会"><a href="#同学聚会" class="headerlink" title="同学聚会"></a>同学聚会</h3><ul>
<li>与北大生科帅哥在商场挑衣服，邀请一家店的售货员去另一家店看鞋搭配上身</li>
<li>三人狂吃自主烤肉长达三小时</li>
<li>与复旦广告学美女朋友在长沙丰盈西里探店</li>
<li>陪同ICL术后朋友打桌球（对还是那三个人）</li>
<li>高中小组F4聚会！经典复刻</li>
</ul>
<h3 id="马来游记"><a href="#马来游记" class="headerlink" title="马来游记"></a>马来游记</h3><p>锐评：虽然KL五星酒店很便宜，但城市建设与公共治理你是真的比不上隔壁Singapore啊（尤其是去年在隔壁过年，感受尤为强烈）</p>
<p>一家人进行着时间利用率最低性价比最低的度假（但也有别样的风味，度假嘛是这样的</p>
<p>体现为，在最后一天double decker时发现每一个知名景点我们都去过至少两遍了，比如武吉免登（在那个麦当劳路口来回过至少五遍）</p>
<p>Langkawi人蛮少的，珍南沙滩也很舒服，但是海水实在是不怎么清澈，浮潜潜了个寂寞，不过奶油大虾特别好吃！强推卓峰海鲜餐厅的奶油老虎虾（我们去吃了两次）</p>
<p>专门为本次独家购入一台<code>__DJI FLIP__</code>,飞行重任自然落到我头上了，只能说想好好运镜尝试拍大片，但是技术不允许()</p>
<h3 id="春节档电影"><a href="#春节档电影" class="headerlink" title="春节档电影"></a>春节档电影</h3><h4 id="哪吒2"><a href="#哪吒2" class="headerlink" title="哪吒2"></a>哪吒2</h4><p>票房爆了，我也不想过多讨论，只是我个人感觉立意不比第一部，或者说我更喜欢第一部，但视效没得说。</p>
<h4 id="唐探1900"><a href="#唐探1900" class="headerlink" title="唐探1900"></a>唐探1900</h4><p>很多人觉得爱国色彩植入太生硬，但我觉得刚刚好，何尝不是一种政治导向呢(doge)</p>
<h3 id="驾考"><a href="#驾考" class="headerlink" title="驾考"></a>驾考</h3><p>我是速通派，去年寒假一晚上速通科一，结果去年十月考C1科目二上坡起步挂了，想着回来也没多少时间练车索性转了C2</p>
<p>于是</p>
<ul>
<li>科二在考场里练了十把就上考场了，第一把直角转弯右侧压线，第二把过</li>
<li>科三考前某晚在考场狂开两小时熟悉线路，考试当天模拟的时候甚至还不记得点火要踩刹车，好在是第四个考，看了三遍怎么都不会出错了，一把过。</li>
<li>但是！！！本来打算周五下午去考课四拿证，都想好发什么文案了“是的，我们在一起了”（当天情人节），结果全长沙驾考培训都不上班，运气实在是太差了呜呜呜，估计要等到暑假才有时间回来拿证了……</li>
</ul>
<h3 id="南京"><a href="#南京" class="headerlink" title="南京"></a>南京</h3><p>终于来了心心念念的红山动物园，不知道是我已经看过太多了还是怎么，来之前以为多能体现人与自然和谐共生，“让动物看人而不是人看动物”，结果发现也不过还是个动物园，但是文创确实很好看！不枉我在Bamboomate排队二十分钟。</p>
<h2 id="Thinking"><a href="#Thinking" class="headerlink" title="Thinking"></a>Thinking</h2><p>to be continued……</p>
<h3 id="存在主义哲学"><a href="#存在主义哲学" class="headerlink" title="存在主义哲学"></a>存在主义哲学</h3><p>萨特才是灵魂！！！</p>
<ul>
<li>《存在主义是一种人道主义》</li>
<li><strong>存在先于本质</strong></li>
</ul>
<h3 id="体验主义"><a href="#体验主义" class="headerlink" title="体验主义"></a>体验主义</h3><h3 id="积极心理学"><a href="#积极心理学" class="headerlink" title="积极心理学"></a>积极心理学</h3><h4 id="弗洛姆"><a href="#弗洛姆" class="headerlink" title="弗洛姆"></a>弗洛姆</h4><ul>
<li>爱的艺术</li>
</ul>
]]></content>
      <categories>
        <category>生活随笔</category>
      </categories>
      <tags>
        <tag>旅行</tag>
        <tag>生活感悟</tag>
      </tags>
  </entry>
  <entry>
    <title>日程</title>
    <url>/2025/02/21/Daily/%E6%97%A5%E8%AE%B0/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="30224aae8c1f8db3ed2d31e897c04294983052bf72179babcb84ce42f4e342eb">42f59dd9f792a26c4a34d7806b09502b15e80c818b4117c1a3fd15ecdb22223227036deee3bce988e109590438c71e097480c6d3900ed7b2bba35c74cbdccf82c696f33b4b1557dd2d0ec879d2e8a68541d04ce287430a16e8dab8766d85a9d9bac446cdf594cbd56efb8d10d70860749bffe80dbf7848ac9197be2a4fb78c48425be2390bfcd8d4f016437458ce2051c33fe282815e84eda0d6fff3963602a1e0c3e82130a3ddd4147b83c1760a0358be27bef80a13236cadb88f4a24fc787d9f29a0d0c0e40a6b2cea32b9505ea5d82bf8ecc40db470a193292b3cec77cfe264af477d4ac3c01c966ab4f5fa0aa4274e887d96232cc3d8939947ab03f9f1a10c2d3ad34e5a1533ab80c693cf5f63210a760231e79ef4ad194abc77a86776f6977b5f8d571d5cb09c3c335cd7365e84f9d061b91a06405694845ed1d9d761b815b1d200e5391b8370bade70c3cadf83fa8a2612cb7949be48d7c45e7961853645385959195e8638aa7e5a2fbfa9039468580aaa474474ba04efe81baa4893ce61ff349409ec3143ffdefd082d4004f92cab90de35b98c765c5eab7706bd76e3a2b80dbc3e98b0462b78cdc027771b84a31368cfde93244e0dbc032c9423032eccd3a72b56792fd9aac95b08fc5ba01f63744445007b3cbee03847d5877ec074b2b27b6405ddfdf01d864c15a6ea20a309fa71ba8abfae3dfc6b8126f7254883041743a9f88f256637329420a3efe7763b3ae89a21273773674fd464102cb80fa98c3aae64569575fa83aa0ad0233c9594dec1f1bc4fd542779dd0b24be599c03073851320be5a8195694271f20931c9ec10674d1a221159363f0f419049f50cba31bca820bb6e05a99b0a29af0a82e242abbd626a6e4a7da838cbe02d1f9c596683a9e0a1b8a9a85af26c5c8aa6884e75a82ded52c0da35ed2a5df49d8bfb91d89f100868ddaf2ac86c823bfa8ebcce56993b383fe73fd845455a3b49412c095f41c8d41f971c3d394bfef67de73f487d514056203dd625465e0e91e6433ea57df6448e24452678fc307c35d7db586576a169d42990d6c35e8948948ed4c9cb890ba0779a5c5643cce47a25956d0e02b194675963784f724704fc8557275887c209d43b68ebc45810c7306c4a376191b603e05fe363ad3ea629fdbb4f804a00cd85ad4be3ef1ff0ce364d22b1bd032ba4d3536d4a090cc0779ffb059a6ea5486bc1557d0fc29aca6b9fb0f20cb40f41f01998ccb33dc8b96d8c22bcd60d017b50a3f4c4fcee058ca914eca3da0bf638524239b1f80b99d76fecc02678055d1f1c143a7ed0f893f8092364b30f419b42c6f2cc4a3c8a7f44943336ea2f451f713d6d9065cbbf3c658dab0f4227caeccce21776ab5acb87da2a9d48410b326d288240ef7b30f683c47f7aec89dd5561cf62fdf193028344ae24efd98d2e87f11188abd3abc064fc6e2a3e8cc0fd9112d5dda100c6ad999725d028af22313b32fa4508826705c71c73e2c88065c126ef748992ba279a3a653d41e150079920ac1f584656cf0900c4cc3341de34deda2c1797717d6afa8ae86597ba955c56d205c3e9f2a5b673b5bc82b16e40fc6049bf841ac0997a5aa3b2dcb9cac9a810e2ebe2ceed31711879fe470cfddc5c0e68555f0e4294de5783e1b31c63f24b43c1182331e08ee8e98547e6cea58f8ed8fbbdd6a4cd723e89882a9cdb1401aaf37c15c23469663d620211bba16b5c378a145babd2748c6184347fe962bb66f32c12a0bc20ee5560bfe689826c5861ff4a24edb9d345d522dcdbad682d3ce6c9e70abee125f4c8ba62ce40cb3245e234967240b41928d56da30b0d156fe7c462ec8a4e63a4c97e6ac5cafab20ad8039b8088bceb78ba8e88a78987b7fe99f1da08cb5b7c504a29f6d1adf51577c61afc6c3644a4b8f6db775c8deaff60375f544d83e19267a3dcbf82310bae77d2a82dca11317d5b0ab91e54586a0c16d7c720b6edf403388bccc0bf02c304e7c84520c1f683f142f110d46131ea3fc9e364d00a3f741318d0de46558e9ebc81bbce6a525ab8295188bd2f53696dcb0fbbae3b9fbfbe16efbdb4e68ae3c7c0bb6366978913deb25465e0773777a66846f175791bec63611af7bce95ceba453aefb92e07ff3c2078568d72199d28fb6a313fff18b3ffb29740e1aad066d7199c234e15f40cc47931cf1b1641fb166d1466c6151485ef24f3eab94ad9a5cd97bf0ac754c84b6161addaeddd0dadeb91afd0f1fe05f540d89974f7357c4425be971b8d15d4cf2554d8bab6500480934f664399d94f8275a6cdbb73bf7dd2795a94bc63767db32e9f2e3793808f02830cbc5ed3df35148f900fe7167c968b00de85c60a0e2972f97999f2b6cbbb36a3a6d70d7771744fd087313fa7864927002faffff47ab18509231f39d3d071865ccedd107fbe616ce9bcf2c283377f64abb5633efc3a830889b6c39a0186e6b075a6d97c53a7b84ad76bed2cac07a1a0b790eeb3ad2c37abf6da2e48921cfbb9ab928bc4160b09f8bc9866455f0091566f26d7ec988abef794eade09105201a4eebf0633d18beffcdff55eb78f832734db0eae42b7e5654be746ad5668a159124467df170474283e54744016f8683727ac35a89a0efd929b7a3c69c06ffe7ee1c9322db35ce3397e7f86d02ab22d43c6306fd880f76e668737d96ab2d01f5fff6196e8ca1bc0f51ff56b89737fe15af38b90f374c1debe4f5f6989dbb50ef21b6bbf005cc40a380cc6658ab7bcad013153d76f01d4f12cc47136bf83b8b421f63919efa8a33c7d1a35a996509a9d2f43a9469c977a43ad513e3c51b67d88d786b1038921869d651eea3a20930522b181ba2b2e87abd26925b0fbf233e2f7a09948024eafb6234af0f372d81c647779640fb52bf053a5804f3bf073f5047837df244131f8020a86f7bd5bb665ce2920280ab54f692e78ac5c70c99f8e75f84595b2ac94d1d7107e6e74df373db364a574c326dd64b3e5eebae28ff8255910cd31f36f57f79bc33ad3976a2dbb488199400f04806fe53a9f4bf563f05763e9a747571766311f3e57c1f1ab94578ec1a6090bd83bb0b760b40588b1791e82e2f369ad5dde1dbfc37bce89ec5387384bdeeeeade4618da8711d6412e3b701305bbbff5522a9427150ab4ffe2fb420732234528bba88dcb6c8a91fd30466e82b4a122c88cd122ffb82303fde6c2225dafcbd684185fcafa97d31426c62d7cd13a12b20a1cce3b05d33be53f83c46144ef8f2bb76b6619050321c0614847709695fb107a08ac28368132456c187dd62357eb70caea98aa8a75e969de1586913d47139092df702c615ec99c490e9f89bbb76e2a70b8af0055677be2e2c2e473c3dd71f44d05d232e4c477f46d397c3e52e91dde041969fdca4409664d652ebf39465f8fc54feb31b610088e9eec57c852a5bd5a58bd6c4d1fd53b1295b78299bacddee784a3f65194ef0f340fb2540b2b77854cd36094187d0385e061d97c4288fc5e660455f1cb4449b2bf26b6af0b845a13d2e89c2987c4c633c77179a57d7eaf0e223677656bb576edc4127c3899d8484b1d44b3547430119837619d55409ee464683220a83e5ae0562ff47e0a1a1e36a71bd50853023cd691600db35bc2589286e5acb528026ad183a5f7a2e64f7a7e574e51d465838e80beb5a928f37d260862d75691090d723a949b7c6c7a1fd3af65b0c64ff21c2389b52ac89e41985990f007c2481b88b2f870a40bf9bf1cf3d4fe8620e654244452251cee96da21c6d1314a2e9eee89b902e361df5d0024dc7d25e09f9731d42e039a328201b361f32ee19698b610294fe0805f6424d5db1b48094691492618bedbeff58c30534bed7efb77ee57e03a2287269bc21fe238701c9e1004858223fb3a90c2ad295c99b81036853b2a0417229cd9d4977ad9c33c4a47c12c04f2ea9e02f54ef8c4c8e99fc4bc5c41341a00b1ac053155469bf596b9fe9932c4ecb28f0c8907158d99f83b1311d8f9fb13cc6e7565bc0d63d2abad11fb74d1cd5a62fc86377f21ce3aef7ccdf6db4cdbde19466c897b80dfb70515b559d18c32b5956e57b15b057772137eb6d6f786a59bf8c0cd131f7b47c671bf3074baa4acbbdbc33e10f807f2a6a28b2e90ffa62f16bf66a133e084072dbe6e9100c24de0ca66a6311e8bf8866c46a5af22cd39c02c25e407d4f4904f82ada89b5349e5898a671d80381ff2946b35c5c7575bacb2bd325bc6f675aae7469a5947918048a5fa47fdada4cd97110f3296876720e03b89cf8c6f8c8faf9aa85b55da5f2580c80b3bc0f8ecddedf5065891eae32f93ec58251210f5399342b397e7707c29a18fa5ca113ea3a94c2458ce43cde29fcb5c40065eb4575acd099ed58bed9dee1948a06a06ab82f4aaa335b7312b32be2e0a2dd2ffd827d87cdaa837740783048fcb489d082214c1d3fd508ad6fd00b08bc421c7d5120c8ba982adb533243758a2a0d1ac6d167da767550ea8ce6f88c78791da98f62558fb7b0eb05059249ff6aeac9212e53ad53b5b31080d4d4fd0e60bec79743304993bfcec0555dec9608dd879eaa34d496fa6ad023c409acdb0b158223701ccb88baab7bd99cec149abd65f5fd0078931f9707b1b51ef608bb35e2d9e489caffd92e73e02dac5e5bedb694601db83a1e403475529c918079cbac590d0ebf328c5350988890d3e27213b75319117d607b88d600d5f3d33fb050d462c9556db677908230e6b04a48339a33a8ea44365b502a7e0755aa807347019950d41d25c875575e982b013f9e0bd60c7aba4c8ca3eee4b02a90b539cbf2153dab1ec4d7a9fa4ab1437a9552687151c2bca974671c73e704c07fc903bd9c9bfae84d75fa99d077feaab2c80ec064f50720b56da85d035c72a00289dab7a5ae03c25c729bf9993a203acda644314516baa6d9535bccc9c51265e9100ad4f5b3f49473b32456c44dcd8b2d79418702bedef55532232b178abbd30fd9111b58278b9ac89c03b31b6452234ef4d1c10d6ab6bfada97d92881d6bdf7cbddfd6526299918054d4f8e13f9dbb6886968da1a7779fb96f87ec39deee58012911687440cb97e9653bd1cd3fff167a24db3a20047ff2ebaf599feaa3c7a6ecb630db5537dfdddb574b312d003605ea68897101424e75b162f601ca35a79c089c818a89d09d58a607676e4303ed03fc3dc6990981e1971b0162b18f860949a49dcfcc9899850d9b040f71bf5910dd55deae82694e1ba165987f6d7d86ca54426c7c2e5ac52f823267c4e81f1e36d27270428870c0db65a133e41d2b08afa887abe40751fa07fac2e2ae95ca6b7e0d42a3e820b7a9ce60940d89a05b0c5cbd9f2c76784d0d85849e4235b1643cc4ffa20ac8646e339f3fe3b544721ee5bdb67cbf81d05a12ca2b8a31a74959e448edff79f3590bfecdb21a2278b7bca9d8d3852700694b3f19f1d8b5ddbc9937d595e6a816681e5dc5eaca7c2b2fe393e952669fe558502c8de5a2034b7492a3f8e4ef789699c83db708e94997381fbe99cd1e3e920b0f09787a269142789db44912429469d5762d7afcaef42e95305fdd94098fdc4770cb3be65afe6b5538a73acf93df219b5ee20e6a8048841dfd3f1040d98d8692fb6f3cfe84bf0fc6a477416bdfd75abc79d5581a4e134befd192f636d3a82b7259b660465ac045c4014d4155e53831b4b8e8c81bd2cb67aae8b36a64e7640c14d8945a9d024553206c569e7a954609ad4415fd908a8a598fd6e017f6b733d456de6f682a131cf2bb19c744513cd81c1e21955e14f20ec222b57fc50a00de1b5a3b3cb51912cdb189339938ec8ceffa9747ee9a8cfb0f1dca2e529b39790b284ae521f64b8cba2a2c75cecabd53ef2199fea3eba852374c4f53a4eb13b93d798c2b32cb879232a660e1d8b69245bdaf3780105f55eee17a6a263e7fd26da208a0eeb674eee3220adc1e7c79603da2f7c69f7afeb1a75e00c9667e5d9dd993641b1bca8440422ff9ad28617dca77f275386e91029971491c9223c3688a6bff2cf86f8faca1813af1f639567d2a6c69380d6bffee5367ce5451acfcc9c64d3fe73e668acdb75aa5573f9f440fe0470a3d915bca943310745feec8a2f7ee575d0e5d723e45ed0ecf8e0fa25ae5681a1965bebc649c70a56807dc832f2490b257592f5f327297fbceed8cb46c7904c5a0937ec0dc9d3418da23d22006e27e56eac64415d85667050efbd734b39637379088947d327612dbb605ffbfbb5e9bd5a194201e6750b4e576324cfe1b72732ccc043f67e7d6ce284efb4e1482053ccc7851a0073965ca5f6d1e447dd07574c2c9db23342890ebaeaf02879eaac1c3328484da7491a623adc1c01dd09b82c6cc1dfde8a3e790bcfc0a40eb85569748677a0d90a2685045777b5747e8025b7ecabf13a0d9f5ff49cab1966bc6ca84115e41fdcc6cfca47e16b6cb76c944285300c8ea7d6df3b4da387d58332ff57e06f769513d1f3f73e63c0a674ff66b3eb59e581d53ecd92ccf10c219048444706c92e50e1fbcfda2292da56ae25a2338df12262ffb084e06560a038b013f30da350dfeed63d7e48f32a76439d24a8a18148271bff2f9bee787b574d2dce3b16588a2ffc8b64a29c6577a2c19c0842b0da2391c00956a1767adc1e4cbd3ec1e8105d45b1d08e3298e48077429121bc8e72e517f74ab4dd6031881030c3b4b71cc6d38a26a46627694fdfb4677d933ee166611a2fa64185ae000f6979fc5a1454ee9837bc706f7f665916d6bbdf453a79377f47e1f6ebeb36a0a5778cadb3a5be9814965c2ad5836466c66e8e146dbe28cc7790742eef8518d12ecb3afdbe6c72f80922c20d52cf459ab2aa52d046de646eb81537bf01ffb139213d3a72a93714b9fa40622adbf8564c2f6447c4af3ec07e1e76e0e65919b39d58b4598a4dbc82bfc337f2e66af4f684e925ec19fa63978490ff8f78cc21b6b7d4287eac9759d5f204661051a1e2424eaf2b86dba8246448f184b8f5dd8985523ce84d8072cf43c636fa8496dcb983a15fb66d404ddf2a2dbe80fa4d15a593880913454d816798e025c52aa699b77fd5a30548f53b79f3b12ca84d6df3594ba8e5786c3ace0fe7acda789893a0ff66643654ffe5c5bc0c8d2a60b7f733f1119bd8668500e561baa99b1ca817f04f11711c6c2d08cd750d52f1e4b8ecd5029ccd37ee79e1406882ba3a1d0ebd288c1528882106af0b3326939190f0059449e701352566fd91147a415c30bd856a3833eec292670aee6ef9c0788041d6120520cd743b142e9751dc3096681bc9c9c4bb59296398dfb6dfd2b919c05f81b092eb8f879cc1c853bdf3ced8e0abcf70fdb6bc3bd0e3e8f92c979b33eda67216809533e6271461b7bdeafe048f7eab80a661f2c22d738f4708c7f81cc92ec72c0c383ecc48d18e8d24806ed38d9e8c119ad251f0d3d67eaedbb56ac8ebd97ba887a738125d6cca83fd912cdda144556fcc90b5c291920f3353d483e66333925066c8d9a8a8e2a3a183f4f63f2e4b4d7304eef27d63056638e819e0ab6e68ad43a94d2b36f9abd30b439536971f871cc38c4adfa82243afa4787e9ab45e1d60417e9c9e626a086d97427283f30be54723a597e84ab11f84a19e7f7aac98fcd0c0e6308570ef22e4d2dc25c38df9753fc8759eca0d53ac96b1384d7629a7ad8d6f1f943aedf5542fd191a355f54dc1bd5b15ea61427e508a81bf77ca314c1989e3d8ac0a89df2746881c96a64b8e5862b07232a09f5aa217e2bfd6de663b4e554ac4d7cb2d5bc3fcdb68e5964e13baace8d478c781bf27db4edfd1257b474a23435f65f17cf1a50d9590342ea1c514f8a93a2265a9e355b14bdd6e049134b35bdd3e6eb28f798c082e127c52f1255913dcdd0d0fefda2e91d53f56c5cc277a21223698be565ad7b10cfa42b21c664b0f375740bf41295e8b29f08675c07381515fdc921fe14a03e23e575e20a5af6eb03697fe1bd037583d601e7e9a2f0de0d7b8c5e8cb4dce15f958595a429b4386f4da4ad21b9db63ec6a6e689f12d7e56c6991a45f777df490a87221733021872c5cf6d5e9306675cf46edbc4e1860eced6efe4e2f846303613f36ec49a8aa733716997d17a3380501e26891c8b461d7463d6a63b7d3e04b95685b04e8c859ef6a0566c8cf1ed8f7eaf9b35f17f3411eb68ffabac6d78375f32097e27e0e04eef29176aabcb476a0538a3a0554e929daf0c584105a78d8b54250db0265b419e777d5f361ccb31e8267fe6056740bb3142614b98af9cb9344cb6c8eb1de5c7502258c2b5f7f62748cecf32f7a52a2ee418ef68cfbdc012adbcf6b744807f18d61c32772342d92413311fd354cbab598f5da2d1549d3f2e8c16c29f35736a6e9f01d564150fcd3d16ebcdf3147d3e97fac1926c56971f7b46d918fba7c415c9ad24eef9c35be6dfdbacbb0e46e647ff51e5a157f3a34060ffe98e5789a087fddecfc3b4599800e3b0ba12fca9a50d99c7e77642641597ace5a76be9d0384039c75623834a53d0be43bc331efe7d656a70eb3f007fc3ed976e1955b901fcb7f141504ddd97a8e3c05443ce556ba807ed674ed6c297f67f5ec2754f34af960fc6dab033196f09f2fa01f7ecccded94a475a511fc2e8a6adf8c0fc22bec712bb79b857f5bff9aff3a3c2e6cfb7de3f555d305f2c04672b4c5a747df836a85236013577459221f141f974151b2526bca375e06119f0f1f207566fc6c48cedd7b1e02a8ed7cf06437977db276221be33d622129641beb54680af424e0bdc0d169b4c42a643fbf7a14b54b2d33df39b9bcdf8a28ca9e2d7f81378302513f89850642406e60f8695b820bc641c93d1a797b9647e4e0d65d8f43db63b686918853d8da98a8fcfa4dab7218379f5d53dc65a5bf1348befb524e430d6378a4f830d12a7a3c5a59ef0c80520bdafdc20b9c60770cecb5953050469582c0c18ee3de85e873d9322b33cd8cb640ee1c01d23cc37ebf405bcc7696d1926a51660ae0a9ff386abe26d0481b4a779646cef391d297f471302bdb6fdfe9aab444ebecd6e479d683767414d31a599ebd6c52143918e77b6c95a2612d7458f03d4d23dcad901cdddbf8c62bf78b9c4d7fb214e2f515672acc36b159a1eec683171f46d3cf8e845222221eb0c92ef591984135eeff7e4171b5cbb5d24da6ec5062d80ec7597253dcbba9113e4569863f2688455f7c0a9da1ddf457bbd7b143b410d3747e2869019559de832bcad5f6c7154d986a023ccfbf53d3025b32bc269514e849d3d467fbe399bda63f6344e70482e2d142b12721ae5563c4e397caa5b8c677f5e080febdde1e1555885846dc7ebaa63ab332f29a1895c736b2be3abda5bfbfd42ea96d89b15115fea4c5c83371c22509bec427912380d7cb1e73a74738f1d7dcf9328b0dee260544d780d4fe0832191bc4964e1ee92148cbf30b098bdad9f0349b711041ab568b94510d97e670b5178ca5cbec0ad8b65f4b852d6315f643a6831d01361540cd5a1ed2e49ab2da7b1a00c8fb3b420a11727d87210d70eb283a3afee70cc660f58c049e4d8a8d8006b4ba9286b7fe8aa2f23338c4e2616c3d1855cc2eb5760011ed67b1034a451d58af207147a5420804f2a165623c478eda39557dc23172bfd11ad21de1a1068fe1c52baede6f3fcf6cb2b913dcb5fd3f9c4860492177a976a14bdf225549199ef614b8b1908e0561a961b6463ea426009cd96242d71d805c6195d9065be37e5b58688aa26b55db858da540e69399a842a2973529d9ecf27f80ea91497b235d99d46fd976c72300d244b84940f3cb0817700bd19b976636d3f16962402cf4b6c3af4c5cf88c2b585835faf289caf0ff76dd937e11b74b5e03d7e365c39fbefa7e98124ccf8e19c7d428dc8a4cced3cb7258e8928977a66efb2ce719cb00f32c2685ee70ec37c0632e4b2596419ab8e0fbb7e99eed83fb29abddead236db64133c4b5546bb791be270673fcb3d1636d908822537e679fe9ef91937d83b572c6b376f2319209844be6a95fb38e9363a1f51a644c304fa6a301fe19934770282ea0ed28adcfbdf3cabb59ba289468625361ce085af4ba86a1e79bc5c00242a74d67c35976af5f01bea01f307c2883b9467d5f6e28b594b8ea1790637b4da0c78641e54a177ead8d82b95665b27126297c8c07e4bb9a3c16388e6e0edc123af821ea6bb084a89dd605f682a97e49627351b6323a1a7ac66b76c90a7654cd71b568c44da01215c6e9dd1a03df80d9e121d3d3e4a0003b5fbfc43ad5728cc8d643a04f9b530f28d99d48875d13bfba0cf6295e5e363b8e61d3ee8ea519b9eaede0b2e0968fb3edd40b03a739de015495642a3315e0ddee15b9e792d6c103e028a451e8b948e4088adb33b4401c174c547d557e96ad38734a9ddcf2829bd68d4cdd8f3e5c946961607fbab26298ef4deb656e6037ebb8890ed72810968d45de62a340936b4e2eaeb06cce1596e950b325b744e97fe07f1f7e42650118bbbaef3c6f7e31fb901d221f0a6cc2db58d70de4abe7ac37e4f8c473c1f35bc2fd0c5b6458be1080d69f5e68009d00d424c2fc056ff0d8666d1de323eea3ca9b37677dbc7dbecb8fb8bafff78dfd65ef416e69f4b19a293cdf8852f8637ea92a0f7321c6b84811ea5be91fb199683ad965d187d38f0a155598ae77d583ba3dbd4d4cc10060a260a81c20b0bd228abba44d113eb18caebad109db47260979a187a17a6d6b93894b46905aa522e5c4f4a3f861900a7721c257f69d939c7a6310d07cf2e620e01740aa27b0782ac9329eaaf6716d95dbe7bea121dff24906d6044fcc761f0aa20027043b266109c8456cd260df031a4480a40adf3911dd7cb9fb5905e736a59608709f93d46a228a0d5db851283241c967e412161c62499a60703e62c8de36c8a7ebe60e1f5efdfd6f120e5480a597b710e4cefe7a905bb07bb74b05e6aaeb8df684671587746baaa36b4ed42b8ff3da8a0216d96f8a581ad63892bc34ca912560061c5b001047494ea50cbc5f4ebc9c6bde77a4afb2300ac5bbbe55df6ff52c2e0c4024470e1e3d87ca93f737e599b7b0c6cce661bd3ca9f480058e7cf9e3c0db01d4023e709bda55d80eabce7fe32409e21e21487f814aa7a3902ce52a5894f672a5e8d2188f2c801c8cc23f9c620541f4b65d551e3dd04a33b9e392ad764568f5b37be7764a50454378dd88dd10548ddf0c446ff962fb3631fc9be66e8433998e80dfd4da8f69a33eca30942ca6c53f5b1bc2f6552100983c5e248317fe5d5827200d5a6edf2e943829ee4afa5fa990037b4ffdbbccc352024d2e5dce07515a39c89632ffc9ac8e9fc65eb6239b17b8880593f7026cdb49f2f1d10a0cd72b0a292f567c96f73d6c560c139bf5f912889208e1f4b2ff24506a4f6314db82cc1e2689ab579a3e270f602669088fc2b745f27b8269475f8c725d7e06efb32555429d4e1a422ef57ecb7974f9e5145f284372587af020e5bedbfe8a0d7f4a7de60569db3ddccdf37372d08636605045ee985b5fc84d8df5092f62617563a2f8d801c174ac6c276ccca2a4100ca6f0bfbb7ef2c771113c721fdd3472da33700499d2464dac13368c7e15dd5f74b5228c1b7a6f5ab81b0e365b2c4609e655ef136257f6c93ca96309e19bc62a9711c64fffa9150b3d288fa4a0e9fb3420fb10d2be6518101f24b8205113974e5edbac339bffdf3e47f9716c5fe6ad492c934d43c38b87ac97866b52eb5ef46aec4ee6627a004b51f07001e288d51064487863e7c3a7439b729e4f78ffdd402312b005b06c830daa6a9260296f517276c2eabd4f0fcec24149e985befeebd06198b20f8e3fa67631e2542e43da17fafdd1b8ce0cb6767f43bb2344538312e57289ca7eac8de78a48c88d348171067c1869d9ae422f5fea6bd736418d72e5a940ae76369fea4eab38dd218cc31dc15be6b7d5b09d742dec6afa8ffaa1ba7f43f10b0a08bab2406bd1703c6bfd6c569f005c9107263fb4d404f98a1da6366a976b3c55f9f38d2cc3b00de3194b143af2793ee4a89b0c7d256db34dd38bd142f695bc513355249a590b36139fb316ce2e32c3d7c41b9f15ee594875719428f46425c0ff6270fdf4ee7f9772e03c65df29d478c317416277ccb441ad787413a8226e098e221cf206f8c6a5196dbc24a59b372cc9b7a9c6db6fb9b6f4228969678decd806a553ef22a383591492a610231bd4b45a80b21cbc1d498aff3bc23f964add2ee2d1dad646483f1b50213803c8586ac7efc77e416e08129e2539e3014346ced7253a506d3a743e45e8d59524b82e7fe45f2c7059b06af37a593f8113d2be85cf1bbe58515eac0f317c89520f3885adf0b495b6bacd512922def2a3b4b8b8c87a5fc974ae45690f1ea4ded548027417ea1cd4a2710ee71a0bbf37e10b16d5effc2028d389fc9c7204d2fc8767475390dcede</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-xray">
      <input class="hbe hbe-input-field hbe-input-field-xray" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-xray" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-xray">Hey, password is required here.</span>
      </label>
      <svg class="hbe hbe-graphic hbe-graphic-xray" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">
        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>
        <path d="M0,2.5c0,0,298.666,0,399.333,0C448.336,2.5,513.994,13,597,13c77.327,0,135-10.5,200.999-10.5c95.996,0,402.001,0,402.001,0"></path>
      </svg>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>日程管理</category>
      </categories>
      <tags>
        <tag>日程</tag>
      </tags>
  </entry>
  <entry>
    <title>OS-02 Functions and Structures</title>
    <url>/2025/02/21/OS/OS02/</url>
    <content><![CDATA[<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Operating systems provide an environment for program executions and services to programs/users<br><span id="more"></span></p>
<p><img src="/images/OS02-overview.jpg" alt="overview"></p>
<h2 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h2><h3 id="User-Interface"><a href="#User-Interface" class="headerlink" title="User Interface"></a>User Interface</h3><p><strong>Shell</strong>: A computer program that exposes an OS’s services to a human user or other programs. OS shells use either a command-line interface (CLI) or a graphical user interface (GUI)<br>An interpreter</p>
<h4 id="CLI"><a href="#CLI" class="headerlink" title="CLI"></a>CLI</h4><p>Shell：</p>
<ul>
<li>Built-in commands: The interpreter contains the code to execute the command. <ul>
<li>直接执行 eg. <code>cd</code></li>
</ul>
</li>
<li>System program commands: The command is a program name. <ul>
<li>查找系统文件执行 eg. <code>ls</code></li>
</ul>
</li>
</ul>
<h3 id="System-Calls"><a href="#System-Calls" class="headerlink" title="System Calls"></a>System Calls</h3><h4 id="Mode"><a href="#Mode" class="headerlink" title="Mode"></a>Mode</h4><ul>
<li>User</li>
<li>Kernel<br>转换：系统调用，中断，异常</li>
</ul>
<h4 id="API"><a href="#API" class="headerlink" title="API"></a>API</h4><p>System calls are mostly accessed by programs via a high-level Application Program Interface (API) rather than direct system call use.<br>性质：</p>
<ul>
<li>易用：无需了解底层实现，直接调用</li>
<li>可移植：API具有跨平台兼容性</li>
<li>安全：直接调用与内核交互</li>
</ul>
<h4 id="Parameter-Passing"><a href="#Parameter-Passing" class="headerlink" title="Parameter Passing"></a>Parameter Passing</h4><ul>
<li>寄存器：快，少</li>
<li>内存表</li>
<li>栈</li>
</ul>
<p>The last two methods do not limit the number or length of parameters being passed 性能损耗</p>
<h4 id="Types"><a href="#Types" class="headerlink" title="Types"></a>Types</h4><h5 id="Type-1-Process-control"><a href="#Type-1-Process-control" class="headerlink" title="Type 1: Process control"></a>Type 1: Process control</h5><ul>
<li>Control the current process: end， abort， execute， load……</li>
<li>Control a different process</li>
<li>Allocate memory and release memory</li>
<li>Debugger</li>
<li>Locks for managing access to shared data between processes</li>
</ul>
<h5 id="Type-2-File-management"><a href="#Type-2-File-management" class="headerlink" title="Type 2: File management"></a>Type 2: File management</h5><h5 id="Type-3-Device-management"><a href="#Type-3-Device-management" class="headerlink" title="Type 3: Device management"></a>Type 3: Device management</h5><h5 id="Type-4-Information-maintenance"><a href="#Type-4-Information-maintenance" class="headerlink" title="Type 4: Information maintenance"></a>Type 4: Information maintenance</h5><h5 id="Type-5-Communications"><a href="#Type-5-Communications" class="headerlink" title="Type 5: Communications"></a>Type 5: Communications</h5><ul>
<li>message passing model 内核中转，离散</li>
<li>shared-memory model 共享物理内存</li>
</ul>
<h5 id="Type-6-Protection"><a href="#Type-6-Protection" class="headerlink" title="Type 6: Protection"></a>Type 6: Protection</h5><h3 id="System-Services"><a href="#System-Services" class="headerlink" title="System Services"></a>System Services</h3><p>In computer hierarchy, system services are higher than system calls.</p>
<p>System services use system calls to interact with the OS kernel</p>
<h4 id="Programs"><a href="#Programs" class="headerlink" title="Programs"></a>Programs</h4><ul>
<li>System Programs：Login program, shell, window manager</li>
<li>Application Programs：Email, web browsers, gaming software, word processors</li>
</ul>
<h4 id="Why-Applications-are-Operating-System-Specific："><a href="#Why-Applications-are-Operating-System-Specific：" class="headerlink" title="Why Applications are Operating System Specific："></a>Why Applications are Operating System Specific：</h4><p>Reason: Each operating system provides its own unique system calls</p>
<p>eg. file format</p>
<h4 id="Services"><a href="#Services" class="headerlink" title="Services"></a>Services</h4><ul>
<li>File management</li>
<li>Status information <ul>
<li>Some systems implement a registry (注册表) - used to store and retrieve configuration information </li>
</ul>
</li>
<li>File modification</li>
<li>Programming-language support</li>
<li>Program loading and execution</li>
<li>Communications</li>
<li>Background Services<ul>
<li>Known as services, subsystems, daemons</li>
</ul>
</li>
</ul>
<h2 id="Operating-System-Structures"><a href="#Operating-System-Structures" class="headerlink" title="Operating System Structures"></a>Operating System Structures</h2><ul>
<li>Simple Structure – MS-DOS</li>
<li>Monolithic (单体)Structure – Original UNIX</li>
<li>Layered Approach</li>
<li>Microkernel System Structure - Mach</li>
<li>Hybrid Systems - windows, macOS, Android </li>
</ul>
<h2 id="Virtual-Machines"><a href="#Virtual-Machines" class="headerlink" title="Virtual Machines"></a>Virtual Machines</h2><p><img src="/images/OS02-V.jpeg" alt="visulization"></p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p><img src="/images/OS02-S.jpeg" alt="topics"></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>OS-03 Process</title>
    <url>/2025/02/26/OS/OS03/</url>
    <content><![CDATA[<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Process is a program in execution.</p>
<span id="more"></span>
<h2 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h2><h3 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h3><ul>
<li>sequential not parallel</li>
</ul>
<p>Process vs Program</p>
<ul>
<li>Program becomes process when an executable file is loaded into memory</li>
</ul>
<hr>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th><strong>程序（Program）</strong></th>
<th><strong>进程（Process）</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>定义</strong></td>
<td>存储在辅助存储（如硬盘）中的静态指令集合，是被动实体</td>
<td>程序执行时的动态实例，是主动运行的实体</td>
</tr>
<tr>
<td><strong>属性</strong></td>
<td>仅包含指令和数据的静态描述</td>
<td>包含程序计数器、内存状态、寄存器值等运行时状态</td>
</tr>
<tr>
<td><strong>生命周期</strong></td>
<td>长期存在（除非被删除）</td>
<td>临时存在（从创建到终止）</td>
</tr>
<tr>
<td><strong>资源需求</strong></td>
<td>无需占用系统资源（仅存储时占用磁盘空间）</td>
<td>需要CPU时间、内存、I/O设备等资源</td>
</tr>
<tr>
<td><strong>控制结构</strong></td>
<td>无控制块</td>
<td>拥有进程控制块（PCB），记录运行状态和资源分配</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h4 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h4><ul>
<li>Stack: local variables, function parameters, return address</li>
<li>Heap: dynamic memory allocation</li>
<li>Data: global variables fixed</li>
<li>Text: code fixed</li>
</ul>
<p><img src="/images/OS03-1.jpg" alt="memory"></p>
<p>Current Process are recorded in PCB</p>
<ul>
<li>Program Counter</li>
<li>Processor Registers</li>
</ul>
<h4 id="Process-State"><a href="#Process-State" class="headerlink" title="Process State"></a>Process State</h4><ul>
<li>New: The process is being created</li>
<li>Ready: The process is waiting to be assigned to a processor</li>
<li>Running: Instructions are being executed</li>
<li>Waiting: The process is waiting for some event to occur</li>
<li>Terminated: The process has finished execution</li>
</ul>
<p><img src="/images/OS03-2.jpeg" alt="process state"></p>
<h4 id="Process-Control-Block-PCB"><a href="#Process-Control-Block-PCB" class="headerlink" title="Process Control Block (PCB)"></a>Process Control Block (PCB)</h4><ul>
<li>Process ID</li>
<li>Process State</li>
<li>Program Counter</li>
<li>CPU Registers</li>
<li>Process Memory Address</li>
<li>CPU Scheduling Information</li>
<li>Accounting Information</li>
<li>I/O Status Information</li>
</ul>
<h3 id="Scheduling"><a href="#Scheduling" class="headerlink" title="Scheduling"></a>Scheduling</h3><p>Process scheduler selects among available processes for next execution on CPU core.</p>
<p>Maintains scheduling queues of processes：</p>
<ul>
<li>Ready queue</li>
<li>Wait queue</li>
</ul>
<p><img src="/images/OS03-3.jpeg" alt="Representation of Process Scheduling"></p>
<h4 id="Context-switch"><a href="#Context-switch" class="headerlink" title="Context switch"></a>Context switch</h4><ul>
<li>Save current process state</li>
<li>Load next process state</li>
<li>Switch to the next process</li>
</ul>
<p>切换时间属于纯开销（overhead），受硬件影响（寄存器数量）</p>
<p><img src="/images/OS03-4.png" alt="context switch"></p>
<p>Scheduler </p>
<ul>
<li>Long-term scheduler: 进程筛选（哪些进程进入ready queue），慢速</li>
<li>Short-term scheduler: CPU调度（运行哪个进程），实现并发，快速</li>
</ul>
<h3 id="Operations"><a href="#Operations" class="headerlink" title="Operations"></a>Operations</h3><h4 id="Process-Creation"><a href="#Process-Creation" class="headerlink" title="Process Creation"></a>Process Creation</h4><ul>
<li>父进程创造子进程（树状结构）<ul>
<li>resource sharing</li>
<li>execution : 并发/父进程等待子进程终止</li>
<li>address space: 复制fork() / 加载新程序exec()</li>
</ul>
</li>
</ul>
<p><img src="/images/OS03-5.png" alt="Process Creation in UNIX"></p>
<h4 id="Process-Termination"><a href="#Process-Termination" class="headerlink" title="Process Termination"></a>Process Termination</h4><ul>
<li>子进程终止（exit）</li>
<li>父进程回收子进程的资源（via wait()）</li>
<li>abort() 级联终止（Cascading termination）</li>
<li>孤儿进程（orphan process）：父进程终止，子进程继续运行</li>
<li>僵尸进程（zombie process）：子进程终止，父进程未回收资源</li>
<li>孤儿进程和僵尸进程的解决方案：init进程（pid=1）</li>
</ul>
<h2 id="Interprocess-Communication"><a href="#Interprocess-Communication" class="headerlink" title="Interprocess Communication"></a>Interprocess Communication</h2><hr>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th><strong>共享内存</strong></th>
<th><strong>消息传递</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>核心</strong></td>
<td>内存共享，直接读写</td>
<td>消息中转，间接通信</td>
</tr>
<tr>
<td><strong>速度</strong></td>
<td>快</td>
<td>慢</td>
</tr>
<tr>
<td><strong>复杂度</strong></td>
<td>高（需同步）</td>
<td>低（系统抽象）</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>单机高频、紧耦合</td>
<td>分布式、松耦合</td>
</tr>
<tr>
<td><strong>同步机制</strong></td>
<td>显式同步（如互斥锁、信号量）</td>
<td>隐式同步（如消息队列）</td>
</tr>
<tr>
<td><strong>可扩展性</strong></td>
<td>差（受限于内存大小）</td>
<td>好（分布式扩展）</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="Shared-Memory"><a href="#Shared-Memory" class="headerlink" title="Shared Memory"></a>Shared Memory</h3><p>Producer process produces information that is consumed by a consumer process</p>
<ul>
<li>Unbounded buffer</li>
<li>Bounded buffer</li>
</ul>
<h3 id="Message-Passing"><a href="#Message-Passing" class="headerlink" title="Message Passing"></a>Message Passing</h3><h4 id="Direct-Communication"><a href="#Direct-Communication" class="headerlink" title="Direct Communication"></a>Direct Communication</h4><p>显式命名</p>
<p>通信链路：需显式建立和关闭</p>
<p>示例：<br>进程 A 调用send(B, “Hello”)，直接向进程 B 发送消息。<br>进程 B 通过receive(A, msg)接收来自 A 的消息。</p>
<h4 id="Indirect-Communication"><a href="#Indirect-Communication" class="headerlink" title="Indirect Communication"></a>Indirect Communication</h4><p>Messages are directed to and received from mailboxes (also referred to as ports)</p>
<ul>
<li>Each mailbox has a unique ID</li>
<li>Processes can communicate only if they share a mailbox</li>
</ul>
<h4 id="Synchronous-（同步）"><a href="#Synchronous-（同步）" class="headerlink" title="Synchronous （同步）"></a>Synchronous （同步）</h4><ul>
<li>Blocking<ul>
<li>发送方直到接收方准备好，一直阻塞，直到消息被接收</li>
<li>接收方直到消息接收，一直阻塞</li>
</ul>
</li>
<li>Non-blocking</li>
</ul>
<h3 id="Pipe"><a href="#Pipe" class="headerlink" title="Pipe"></a>Pipe</h3><p>管道是一种半双工的通信通道，允许一个进程的输出直接作为另一个进程的输入。</p>
<p>Require parent-child relationship.</p>
<h4 id="Ordinary-Pipe-Anonymous-Pipe"><a href="#Ordinary-Pipe-Anonymous-Pipe" class="headerlink" title="Ordinary Pipe / Anonymous Pipe"></a>Ordinary Pipe / Anonymous Pipe</h4><p>数据只能从管道的写入端流向读取端，具有单向性。</p>
<h4 id="Named-Pipe"><a href="#Named-Pipe" class="headerlink" title="Named Pipe"></a>Named Pipe</h4><p>Communication is bidirectional.</p>
<p>No parent-child relationship</p>
<h2 id="Communication-in-Client-Server-Systems"><a href="#Communication-in-Client-Server-Systems" class="headerlink" title="Communication in Client-Server Systems"></a>Communication in Client-Server Systems</h2><h3 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h3><p>Socket is a communication endpoint that allows two-way communication between processes.</p>
<p>IP 地址用于唯一标识网络中的设备，而端口号则用于区分同一设备上的不同网络服务。</p>
<p>Create a socket:</p>
<ul>
<li>Server side<ul>
<li>bind()</li>
<li>listen()</li>
<li>accept()</li>
<li>read() / write()</li>
<li>close()</li>
</ul>
</li>
<li>Client side<ul>
<li>connect()</li>
<li>read() / write()</li>
<li>close()</li>
</ul>
</li>
</ul>
<h3 id="Remote-Procedure-Call"><a href="#Remote-Procedure-Call" class="headerlink" title="Remote Procedure Call"></a>Remote Procedure Call</h3><p>RPC 是一种分布式计算的通信协议，允许一个进程调用另一个进程中的函数。</p>
<p>RPC 通过网络通信，将本地函数调用转换为远程函数调用。</p>
<ul>
<li>本地调用：<ul>
<li>调用本地函数</li>
<li>返回结果</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
</search>
